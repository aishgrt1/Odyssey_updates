{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from odyssey.utils import *\n",
    "from odyssey.core.bigquery.BigQueryGithubEntry import *\n",
    "from odyssey.core.analyzer import InstantiationAnalyzer \n",
    "from odyssey.core.analyzer import ImportAnalyzer as impAn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from odyssey.core.bigquery.GithubPython import GithubPython \n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "otherModuleList = ['sqlalchemy','matplotlib','pandas', 'numpy', 'theano', 'nltk', 'tensorflow', 'pylearn2', 'theanets', 'hebel', 'caffe', 'pybrain', 'brainstorm', 'liblinear', 'libsvm', 'statsmodels', 'scipy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnasGhrab/scikit-learn', 'RPGOne/Skynet', 'beepee14/scikit-learn', 'vshtanko/scikit-learn', 'gclenaghan/scikit-learn', 'vibhorag/scikit-learn', 'pnedunuri/scikit-learn', 'jianpingliu/scikit-learn', 'poryfly/scikit-learn', 'treycausey/scikit-learn', 'mjgrav2001/scikit-learn', 'marcocaccin/scikit-learn', 'bnaul/scikit-learn', 'tmhm/scikit-learn', 'glennq/scikit-learn', 'loli/semisupervisedforests', 'vermouthmjl/scikit-learn', 'robbymeals/scikit-learn', 'alexeyum/scikit-learn', 'Sentient07/scikit-learn', 'simon-pepin/scikit-learn', 'dougalsutherland/scikit-learn', 'zihua/scikit-learn', 'ashhher3/scikit-learn', 'kevin-coder/scikit-learn-fork', 'anurag313/scikit-learn', 'lin-credible/scikit-learn', 'Garrett-R/scikit-learn', 'jjx02230808/project0223', 'rloliveirajr/sklearn_transformers', 'sylvan5/PRML', 'TenninYan/Perceptron', 'ilo10/pattern_classification', 'everysignalinc/heroku-buildpack-python-scikit-learn-git', 'bbengfort/hadoop-fundamentals', 'PythonWorkshop/intro-to-sklearn', 'jljones/sklearn_pycon2015', 'kod3r/sklearn-pmml', 'jmhessel/keras', 'ELind77/gensim', 'trhongbinwang/data_science_journey', 'rsteca/sklearn-deap', 'RaRe-Technologies/gensim', 'scikit-learn-contrib/project-template', 'erichseamon/sklearn_pydata2015', 'dubeyabhi07/clipper', 'Jeff20/sklearn_pycon2015', 'pstrongu93/k-Nearest-Neighbors', 'linucks/textclass', 'odejesush/tensorflow', 'astocko/statsmodels', 'monal94/digits-scikit-learn', 'jpmml/jpmml-sklearn', 'probcomp/bdbcontrib', 'meteorcloudy/tensorflow', 'brandonckelly/bck_stats', 'sbraden/kg_sklearn', 'followyourheart/SFrame', 'yongtang/tensorflow', 'martinpopel/vowpal_wabbit', 'andrejsim/test', 'chop-dbhi/arrc', 'CodeMonkeyJan/hyperspy', 'xho95/BuildingMachineLearningSystemsWithPython', 'lmarchesoti/kaggle', 'dieterv77/statsmodels', 'yafeunteun/wikipedia-spam-classifier', 'gticket/scikit-neuralnetwork', 'ivano666/tensorflow', 'HaebinShin/tensorflow', 'h2oai/h2o-3', 'unnikrishnankgs/va', 'EricSchles/pattern_classification', 'pburdet/hyperspy', 'aam-at/tensorflow', 'josef-pkt/statsmodels', 'gph82/PyEMMA', 'freedomtan/tensorflow', 'girving/tensorflow', 'handroissuazo/tensorflow', 'jcrist/dask-learn', 'ContinuumIO/demo', 'bzero/statsmodels', 'tarasane/h2o-3', 'MechCoder/scikit-learn', 'mugizico/scikit-learn', 'jakirkham/scikit-learn', 'Vimos/scikit-learn', 'deepesch/scikit-learn', 'stylianos-kampakis/scikit-learn', 'nhejazi/scikit-learn', 'MartinDelzant/scikit-learn', 'lesteve/scikit-learn', 'massmutual/scikit-learn', 'mattgiguere/scikit-learn', 'schets/scikit-learn', 'MengLiPKU/scikit-learn', 'petosegan/scikit-learn', 'jzt5132/scikit-learn', 'kashif/scikit-learn', 'joernhees/scikit-learn', 'xiaoxiamii/scikit-learn', 'roxyboy/scikit-learn', 'alexsavio/scikit-learn', 'xwolf12/scikit-learn', 'mhdella/scipy_2015_sklearn_tutorial', 'wllmtrng/udacity_data_analyst_nanodegree', 'SciDevs/heroku-buildpack-python-scikit-learn-git', 'he7d3r/revscoring', 'Diviyan-Kalainathan/causal-humans', 'YuHuaCheng/sklearn-pmml', 'MediffRobotics/DeepRobotics', 'xguse/spartan', 'gsmafra/sklearn-dummies', 'jcrudy/sklearntools', 'Succeed-Together/bakfu', 'jpmml/sklearn2pmml', 'zhmz90/Daily', 'numenta/htmresearch', 'mrcslws/htmresearch', 'mitdbg/modeldb', 'gojomo/gensim', 'wavelets/hyperopt-sklearn', 'CheMcCandless/hyperopt-sklearn', 'jbrambleDC/sklearn_pydata2015', 'MostafaGazar/tensorflow', 'iszlai/sklearn_pycon2015', 'mihirkelkar/BuildingMachineLearningSystemsWithPython', 'jasonszang/DeepLearning', 'tian-zhou/InstrumentSegmentation', 'jankoslavic/py-tools', 'MartialD/hyperspy', 'hsaputra/h2o-3', 'tebeka/pythonwise', 'annarev/tensorflow', 'Purg/SMQTK', 'AnishShah/tensorflow', 'southpaw94/MachineLearning', 'jgdwyer/nn-convection', 'eth-n/tensorflow', 'naoyak/Agile_Data_Code_2', 'bashtage/statsmodels', 'jeenalee/sklearn_pmml', 'YzPaul3/h2o-3', 'orangeYao/twiOpinion', 'fyears/sklearn_xgb', 'megahertz0/tusharedemo', 'jwlawson/tensorflow', 'JohnAshburner/ISBI', 'ainafp/nilearn', 'nikste/tensorflow', 'rgommers/statsmodels', 'detrout/debian-statsmodels', 'jrmontag/Data-Science-45min-Intros', 'jendap/tensorflow', 'duecredit/duecredit', 'percyfal/snakemakelib-core', 'brianmingus/sklearn-emergent', 'luo66/scikit-learn', 'adason/scikit-learn', 'fzalkow/scikit-learn', 'anirudhjayaraman/scikit-learn', 'tosolveit/scikit-learn', 'automl/auto-sklearn', 'Jimmy-Morzaria/scikit-learn', 'nikitasingh981/scikit-learn', 'icdishb/scikit-learn', 'wlamond/scikit-learn', 'mlyundin/scikit-learn', 'sgenoud/scikit-learn', 'jm-begon/scikit-learn', 'rseubert/scikit-learn', 'wazeerzulfikar/scikit-learn', 'pprett/sklearn_pycon2014', 'ngoix/OCRF', 'etkirsch/scikit-learn', 'Srisai85/sklearn_pycon2015', 'nomorewzx/scikit-learn', 'lzamparo/scikit-learn', 'joelby/heroku-buildpack-python-scikit-learn-git', 'amueller/scipy-2016-sklearn', 'samuel1208/scikit-learn', 'MarkAWard/optunity', 'arnabgho/sklearn-theano', 'PepSalehi/scipy_2015_sklearn_tutorial', 'davidzchen/tensorflow', 'EvenStrangest/tensorflow', 'lilleswing/deepchem', 'ViralLeadership/scipy_2015_sklearn_tutorial', 'tudo-astroparticlephysics/pydisteval', 'yuraic/koza4ok', 'calebfoss/tensorflow', 'taknevski/tensorflow-xsmm', 'iluoyi/scikit-learn-in-action', 'computational-class/cjc', 'Adai0808/BuildingMachineLearningSystemsWithPython', 'ntucllab/libact', 'cbecker/LightGBM', 'ogrisel/sklearn_pycon2014', 'dsquareindia/gensim', 'grantathon/computer_vision_machine_learning', 'DoWhatILove/turtle', 'eyadsibai/rep', 'pthaike/SFrame', 'BonexGu/Blik2D-SDK', 'natbusa/geo-services.scikit-learn', 'muskanbararia/Julia', 'godelian/BuildingMachineLearningSystemsWithPython', 'SAGridOps/SoftwareTests', 'cle1109/scot', 'sachinpro/sachinpro.github.io', 'roxana-lafuente/POCs', 'mikedelong/aarhus', 'nixingyang/Kaggle-Face-Verification', 'JingJunYin/tensorflow', 'wzbozon/statsmodels', 'admcrae/tensorflow', 'fmfn/BayesianOptimization', 'wjfwzzc/gensim_demo', 'cxxgtxy/tensorflow', 'notmatthancock/notmatthancock.github.io', 'noelevans/sandpit', 'alsrgv/tensorflow', 'bmabey/pyLDAvis', 'StevenReitsma/kaggle-galaxyzoo', 'zouzias/sklearn-examples', 'giserh/SFrame', 'elaeon/ML', 'HKUST-SING/tensorflow', 'jangorecki/h2o-3', 'jstoxrocky/statsmodels', 'mltsp/mltsp', 'crackhopper/TFS-toolbox', 'relh/keras', 'freakynit/scikit-neuralnetwork', 'StrikerRUS/rgf_python', 'Intel-Corporation/tensorflow', 'natanielruiz/android-yolo', 'mvdoc/duecredit', 'nmayorov/scikit-learn', 'fabianp/scikit-learn', 'toastedcornflakes/scikit-learn', 'BiaDarkia/scikit-learn', 'arabenjamin/scikit-learn', 'harshaneelhg/scikit-learn', 'untom/scikit-learn', 'hsuantien/scikit-learn', 'hsiaoyi0504/scikit-learn', 'abhishekgahlot/scikit-learn', 'kagayakidan/scikit-learn', 'nvoron23/scikit-learn', 'arahuja/scikit-learn', 'hasancansaral/scikit-learn', 'kjung/scikit-learn', 'samzhang111/scikit-learn', 'larsmans/scikit-learn', 'fbagirov/scikit-learn', 'ryfeus/lambda-packs', 'aflaxman/scikit-learn', 'hrjn/scikit-learn', 'odewahn/sklearn_pycon2015', 'vene/scikit-learn', 'dsullivan7/scikit-learn', 'daviddao/luminosity', 'cbrnr/scot', 'combust/mleap', 'zorroblue/scikit-learn', 'sumspr/scikit-learn', 'AlexanderFabisch/scikit-learn', 'idlead/scikit-learn', 'automl/paramsklearn', 'bensinghbeno/design-engine', 'dianachenyu/linear-svm-squared-hinge-loss', 'ktaneishi/deepchem', 'scikit-learn-contrib/py-earth', 'jianantian/entity_recognizer', 'arthurmensch/scikit-learn-sandbox', 'riteshkasat/scipy_2015_sklearn_tutorial', 'gnublet/py_explorations', 'huangshenno1/algo', 'ywcui1990/nupic.research', 'nishantsbi/pattern_classification', 'ThomasMiconi/htmresearch', 'tillahoffmann/tensorflow', 'tobegit3hub/deep_cnn', 'renyi533/tensorflow', 'mrry/tensorflow', 'zhuango/python', 'actlea/TopicalCrawler', 'NovaSyst/chocolate', 'bhmm/bhmm', 'stczhc/neupy', 'Rossonero/bmlswp', 'mortada/tensorflow', 'mjgrav2001/rep', 'SnakeJenny/TensorFlow', 'ZhukovGreen/UMLND', 'adammenges/statsmodels', 'EsriOceans/oceans-workshop-2016', 'wkal/brain4k', 'benoitsteiner/tensorflow', 'zhangyafeikimi/LightGBM', 'automl/HPOlib2', 'recipy/recipy', 'bert9bert/statsmodels', 'hitlonewind/PR-experiment', 'KhanSuleyman/scikit-neuralnetwork', 'jakirkham/lazyflow', 'nightjean/Deep-Learning', 'Berkeley-MIDS-ML/sklearn-clustering', 'abenicho/isvr', 'JohnLangford/vowpal_wabbit', 'ravindrapanda/tensorflow', 'DucQuang1/BuildingMachineLearningSystemsWithPython', 'jmorton/yatsm', 'johny-c/pylmnn', 'alvations/USAAR-SemEval-2015', 'lmatthieu/myvw', 'AndreasMadsen/tensorflow', 'honzas83/kitchen', 'bnaul/mltsp', 'zhenv5/scikit-learn', 'nelson-liu/scikit-learn', 'spallavolu/scikit-learn', 'RachitKansal/scikit-learn', '0x0all/scikit-learn', 'vinayak-mehta/scikit-learn', 'diyessi/scikit-learn', 'olologin/scikit-learn', 'yyjiang/scikit-learn', 'marscher/bhmm', 'jmschrei/scikit-learn', 'perimosocordiae/scikit-learn', 'hmendozap/auto-sklearn', 'robin-lai/scikit-learn', 'moutai/scikit-learn', 'Nyker510/scikit-learn', 'arjoly/scikit-learn', 'sanketloke/scikit-learn', 'hdmetor/scikit-learn', 'Myasuka/scikit-learn', 'Djabbz/scikit-learn', 'dbrgn/heroku-buildpack-python-sklearn', 'gotomypc/scikit-learn', 'joshbohde/scikit-learn', 'xubenben/scikit-learn', 'hainm/scikit-learn', 'ominux/scikit-learn', 'phdowling/scikit-learn', 'djgagne/scikit-learn', 'liberatorqjw/scikit-learn', 'vtesin/sklearn_tutorial', 'seckcoder/lang-learn', 'ZenDevelopmentSystems/scikit-learn', 'fabioticconi/scikit-learn', 'bssrdf/sklearn-theano', 'KhanSuleyman/scipy_2015_sklearn_tutorial', 'alexchao56/sklearn-theano', 'brianjwoo/sklearn_pycon2014', 'rhiever/scipy_2015_sklearn_tutorial', 'Twangist/log_calls', 'oesteban/mriqc', 'bmmalone/as-auto-sklearn', 'nixingyang/Kaggle-Competitions', 'vighneshbirodkar/sklearn-stub', 'miguelfc/marble', 'aufziehvogel/kaggle', 'wbap/V1', 'pombredanne/vowpal_wabbit', 'gtrichards/PHYS_T480', 'TobyRoseman/SFrame', 'haijieg/SFrame', 'wlsc/tensorflow', 'snnn/tensorflow', 'vlaufer/candy_crush_bot_mac', 'scot-dev/scot', 'sdvillal/whatami', 'josh-howes/sklearn-stacking', 'dnjohnstone/hyperspy', 'trendelkampschroer/PyEMMA', 'zxytim/sklearn-cmdline-wrapper', 'sillvan/hyperspy', 'seaotterman/tensorflow', 'RayMick/SFrame', 'MohammedWasim/pattern_classification', 'henry0312/LightGBM', 'trufanov-nok/vowpal_wabbit', 'steinam/teacher', 'JohnVinyard/zounds', 'gregsharp/vowpal_wabbit', 'msarahan/analyzarr', 'mkliegl/custom-sklearn', 'bhargavvader/gensim', 'belkhir-nacim/smac_python', 'XiaoLiuAI/RUPEE', 'gnieboer/tensorflow', 'DavidNorman/tensorflow', 'jart/tensorflow', 'hfp/tensorflow-xsmm', 'sidmukherjee5/pattern_classification', 'Intel-tensorflow/tensorflow', 'hlin117/statsmodels', 'h-mayorquin/competitive_and_selective_learning', 'leonardhussenot/spn', 'wangjohn/wallace', 'lixiaosi33/-Classification-on-Chinese-Magazine-', 'mengxn/tensorflow', 'nkhuyu/SFrame', 'bernardndegwa/pattern_classification', 'kyoren/https-github.com-h2oai-h2o-3', 'DerThorsten/seglib', 'jseabold/scikit-learn', 'fredhusser/scikit-learn', 'frank-tancf/scikit-learn', 'kernc/scikit-learn', 'jakobworldpeace/scikit-learn', 'MartinSavc/scikit-learn', 'florian-f/sklearn', 'andrewnc/scikit-learn', 'sarahgrogan/scikit-learn', 'rahuldhote/scikit-learn', 'rishikksh20/scikit-learn', 'wanggang3333/scikit-learn', 'wallygauze/scikit-learn', 'cdegroc/scikit-learn', 'depet/scikit-learn', '3manuek/scikit-learn', 'mfjb/scikit-learn', 'ilyes14/scikit-learn', 'iismd17/scikit-learn', 'jorge2703/scikit-learn', 'ilo10/scikit-learn', 'lrivas2/scikit-learn', 'amueller/sklearn_workshop', 'laic/gensim', 'jcrist/dask-searchcv', 'Yu-Group/scikit-learn-sandbox', 'jamesmishra/nlp-playground', 'sandeepdsouza93/TensorFlow-15712', 'McCabeJM/sklearn_pycon2014', 'Allardvm/LightGBM', 'LewBurton/sklearn_pycon2015', 'ajtulloch/sklearn-compiledtrees', 'vasudevk/sklearn_pycon2015', 'BrianPin/tensorflow', 'dbendet/sklearn_pycon2015', 'SeldonIO/seldon-server', 'Kongsea/tensorflow', 'sightmachine/LightGBM', 'smrjan/seldon-server', 'harish-garg/Machine-Learning', 'jpata/ROOTDataHelpers', 'uwescience/sklearn-forest-ci', 'beeva-fernandocerezal/rasa_nlu', 'pchmieli/h2o-3', 'lukas/scikit-class', 'jat255/hyperspy', 'SidSachdev/SFrame', 'alexshires/ml', 'benoitsteiner/tensorflow-xsmm', 'elingg/tensorflow', 'sjperkins/tensorflow', 'gunan/tensorflow', 'NicovincX2/Python-3.5', 'schartz/BuildingMachineLearningSystemsWithPython', 'chrisjdavie/shares', 'imatge-upc/affective', 'arranger1044/spyn', 'rakeshkurakula/pattern_classification', 'chrinide/optunity', 'enlighter/learnML', 'alisidd/tensorflow', 'GoogleCloudPlatform/ml-on-gcp', 'francisco-dlp/hyperspy', 'The-Seth/pattern_classification', 'tsterbak/scikit-stack', 'JVillella/tensorflow', 'hyperspy/hyperspy', 'Weihonghao/ECM', 'jhseu/tensorflow', 'ucbrise/clipper', 'bluemonk482/tdparse', 'Barmaley-exe/scikit-learn', 'abimannans/scikit-learn', 'kaushik94/scikit-learn', 'chrsrds/scikit-learn', 'DonBeo/scikit-learn', 'pkruskal/scikit-learn', 'chrisburr/scikit-learn', 'ahoyosid/scikit-learn', 'lenovor/scikit-learn', 'fspaolo/scikit-learn', '466152112/scikit-learn', 'Akshay0724/scikit-learn', 'Sklearn-HMM/scikit-learn-HMM', 'devanshdalal/scikit-learn', 'ningchi/scikit-learn', 'imaculate/scikit-learn', 'tz70s/scikit-learn', 'yarikoptic/scikit-learn', 'mxjl620/scikit-learn', 'TomDLT/scikit-learn', 'trungnt13/scikit-learn', 'jaksmid/gensim', 'wbap/BriCA1', 'edublancas/sklearn-evaluation', 'MLWave/auto-sklearn', 'ville-k/tensorflow', 'N-Wouda/statsmodels', 'wdm0006/sklearn-extensions', 'summanlp/gensim', 'jeffzhengye/pylearn', 'festeh/BuildingMachineLearningSystemsWithPython', 'vlad17/spark-sklearn', 'jakevdp/sklearn_pycon2015', 'caidongyun/BuildingMachineLearningSystemsWithPython', 'blauigris/magic-pylearn', 'loisaidasam/gensim', 'gautam1858/tensorflow', 'fukatani/rgf_python', 'cassebook/cassebook.github.io', 'edhuckle/statsmodels', 'tadejs/autokit', 'YihaoLu/statsmodels', 'Aggieyixin/cjc2016', 'fdft/ml', 'willianbriotto/python_training', 'AlexEne/CCrush-Bot', 'dato-code/SFrame', 'andrewtvuong/PythonDataScience', 'edublancas/pipeline', 'subutai/nupic.research', 'wkfwkf/statsmodels', 'ibmsoe/tensorflow', 'psi-project/sklearn-wrapper', 'ijat/Hotspot-PUTRA-Auto-login', 'yarikoptic/duecredit', 'jjgoings/cq_realtime', 'tzukuoh/vowpal_wabbit', 'mathemage/h2o-3', 'dfd/ml_utils', 'nvoron23/statsmodels', 'benoitsteiner/tensorflow-opencl', 'w-garcia/BugClustering', 'Carmezim/tensorflow', 'bavardage/statsmodels', 'RecipeML/Recipe', 'printedheart/h2o-3', 'tomasreimers/tensorflow-emscripten', 'murali-munna/pattern_classification', 'abhitopia/tensorflow', 'gojira/tensorflow', 'Achuth17/scikit-learn', 'rajpurkar/heroku-buildpack-python-sklearn', 'bwignall/scikit-learn', 'ClimbsRocks/scikit-learn', 'luispedro/scikit-learn', 'btabibian/scikit-learn', 'miclovich/scikit-learn', 'devs1991/test_edx_docmode', 'voxlol/scikit-learn', 'Aasmi/scikit-learn', 'nesterione/scikit-learn', 'justincassidy/scikit-learn', 'rajat1994/scikit-learn', 'vybstat/scikit-learn', 'lazywei/scikit-learn', 'AlexRobson/scikit-learn', 'ldirer/scikit-learn', 'pprett/scikit-learn', 'JesseLivezey/sklearn-theano', 'sds-dubois/scikit-learn', 'erwin00776/comment_label_worm', 'JosmanPS/scikit-learn', 'flightgong/scikit-learn', 'mehdidc/scikit-learn', 'maniteja123/scikit-learn', 'tianyupu/hons-thesis', 'marcsans/cnn-physics-perception', 'podshumok/sklearn-describe', 'jayhetee/auto-sklearn', 'Ginkgo-Biloba/Misc-Python', 'dariodata/learn-scikit-learn', 'deeplycloudy/lmatools', 'wkuling/sklearn_pycon2014', 'HRZaheri/sklearn-theano', 'max291/pattern_classification', 'Capepy/scipy_2015_sklearn_tutorial', 'maythapk/sklearn_pycon2014', 'rjurney/Agile_Data_Code_2', 'munichpavel/risklearning', 'rladeira/mltils', 'scikit-learn-contrib/categorical-encoding', 'GehenHe/Recognize-Face-on-Android', 'hal3/vowpal_wabbit', 'mhdella/sklearn_pycon2015', 'palandatarxcom/sklearn_tutorial_cn', 'voxlol/pattern_classification', 'kpolimis/sklearn-forest-ci', 'markovmodel/PyEMMA', 'databricks/spark-sklearn', 'McCabeJM/sklearn_pycon2015', 'concord/ml', 'choupi/NDHUDLWorkshop', 'mathhun/scipy_2015_sklearn_tutorial', 'h-mayorquin/pycuda_test', 'RamaneekGill/Twitter-Sentiment-Analysis', 'joegomes/deepchem', 'pvigier/sa', 'amueller/scipy_2015_sklearn_tutorial', 'davidlmorton/spikepy', 'ylow/SFrame', 'bakfu/bakfu', 'jaganadhg/azureml-pretrained-sklearn', 'codeaudit/Variational-Autoencoder', 'shuggiefisher/brain4k', 'RasaHQ/rasa_nlu', 'magnunor/hyperspy', 'ZhangXinNan/tensorflow', 'tgquintela/pySpatialTools', 'claesenm/optunity', 'jgdwyer/ML-convection', 'lucafon/ArtificialIntelligence', 'rishuatgithub/MLPy', 'dllllb/ds-tools', 'desihub/desiutil', 'bond-/udacity-ml', 'IRC-SPHERE/sklearn-Infer.NET-wrapper', 'dongjoon-hyun/tensorflow', 'ChadFulton/statsmodels', 'YulongWu/my-utils', 'sabertazimi/Awesome-Notes', 'kshedden/statsmodels', 'eerwitt/tensorflow', 'jgors/duecredit', 'gerberlab/mitre', 'AstroHackWeek/AstroHackWeek2015', 'persepolisdm/mac-package-build', 'llhe/tensorflow', 's1na/magpie', 'XueqingLin/tensorflow', 'wdurhamh/statsmodels', 'pyannote/pyannote-algorithms', 'hgrif/ds-utils', 'xuewei4d/scikit-learn', 'WangWenjun559/Weiss', 'betatim/scikit-learn', 'jereze/scikit-learn', 'GbalsaC/bitnamiP', 'chaluemwut/fbserver', 'The-Seth/scikit-learn', 'gooeyforms/scikit-learn', 'jmetzen/scikit-learn', 'Tong-Chen/scikit-learn', 'hitszxp/scikit-learn', 'zorojean/scikit-learn', 'mrshu/scikit-learn', 'pianomania/scikit-learn', 'rrohan/scikit-learn', 'ky822/scikit-learn', 'jaidevd/scikit-learn', 'rohanp/scikit-learn', 'sourabhdattawad/BuildingMachineLearningSystemsWithPython', 'rhiever/sklearn-benchmarks', 'nomadcube/scikit-learn', 'trankmichael/scikit-learn', 'ChanderG/scikit-learn', 'huobaowangxi/scikit-learn', 'lucidfrontier45/scikit-learn', 'CforED/Machine-Learning', 'Obus/scikit-learn', 'agramfort/scikit-learn', 'cainiaocome/scikit-learn', 'pypot/scikit-learn', 'rain1024/sklearn_tutorial', 'NunoEdgarGub1/scikit-learn', 'sebp/scikit-learn', 'kastnerkyle/sklearn-theano', 'minhpqn/sklearn_pydata2015', 'jingfengli/scipy_2015_sklearn_tutorial', 'JPFrancoia/scikit-learn', 'sdpython/ensae_teaching_cs', 'lmc2179/explain_sklearn', 'ecairol/sklearn-amazon-reviews', 'ageek/confPyNotebooks', 'KyriacosShiarli/Variational-Autoencoder', 'edublancas/dstools', 'automl/HPOlibConfigSpace', 'jjas0nn/solvem', 'CacconeLabYale/snakemake-pipelines', 'edublancas/sklearn-model-evaluation', 'suiyuan2009/tensorflow', 'Quadrocube/rep', 'rmdort/clipper', 'imyeego/MLinPy', 'hoytak/SFrame', '3manuek/pattern_classification', 'cg31/tensorflow', 'dssg/diogenes', 'chris-chris/tensorflow', 'ywcui1990/htmresearch', 'gibiansky/tensorflow', 'nwiizo/workspace_2017', 'huanzhang12/LightGBM', 'ThomasMiconi/nupic.research', 'subramgo/scikit-learn', 'huongttlan/statsmodels', 'marscher/PyEMMA', 'echalkpad/t4f-data', 'nickcdryan/rep', 'qrsforever/workspace', 'nguyentu1602/statsmodels', 'saketkc/statsmodels', 'polentozer/testing_0', 'dhalleine/tensorflow', 'tntnatbry/tensorflow', 'TinghuiWang/pyActLearn', 'pavelchristof/gomoku-ai', 'napsternxg/pyLDAvis', 'stuarteberg/lazyflow', 'cauchycui/scikit-learn', 'tomlof/scikit-learn', 'rahul-c1/scikit-learn', 'lancezlin/ml_template_py', 'tdhopper/scikit-learn', 'chyikwei/scikit-learn', 'jakevdp/scikit-learn', 'mvdoc/scikit-learn', 'smartscheduling/scikit-learn-categorical-tree', 'thientu/scikit-learn', 'ogrisel/scikit-learn', 'elkingtonmcb/scikit-learn', 'waterponey/scikit-learn', 'Windy-Ground/scikit-learn', 'glemaitre/scikit-learn', 'mhdella/scikit-learn', 'abhisg/scikit-learn', 'lbishal/scikit-learn', 'valexandersaulys/airbnb_kaggle_contest', 'shyamalschandra/scikit-learn', 'quheng/scikit-learn', 'jmargeta/scikit-learn', 'Eric89GXL/scikit-learn', 'astro4dev/OAD-Data-Science-Toolkit', 'f3r/scikit-learn', 'yanlend/scikit-learn', 'uglyboxer/linear_neuron', 'UNR-AERIAL/scikit-learn', 'linan7788626/scipy_2015_sklearn_tutorial', 'nickgentoo/scikit-learn-graph', 'fsgp/scipy_2015_sklearn_tutorial', 'bpgriner01/sklearn_pycon2015', 'TeamHG-Memex/eli5', 'minesense/VisTrails', 'brchiu/tensorflow', 'KaiWeiChang/vowpal_wabbit', 'lampts/sklearn_pycon2015', 'implus/scipy_2015_sklearn_tutorial', 'michaelbrundage/vowpal_wabbit', '4Catalyzer/tensorflow', 'CloudbrainLabs/htm-challenge', 'lesteve/duecredit', 'robotcator/gensim', 'bsipocz/statsmodels', 'waynenilsen/statsmodels', 'slchen2014/h2o-3', 'hjanime/VisTrails', 'arokem/PyEMMA', 'tongwang01/tensorflow', 'quietcoolwu/myBuildingMachineLearningSystemsWithPython-second_edition', 'moonbury/pythonanywhere', 'yaroslavvb/tensorflow', 'neilhan/tensorflow', 'luispedro/BuildingMachineLearningSystemsWithPython', 'manashmndl/pattern_classification', 'nilbody/h2o-3', 'jrmontag/mnist-sklearn', 'tobegit3hub/deep_recommend_system', 'shaypal5/pdpipe', 'scr4t/rep', 'appapantula/pattern_classification', 'jrpretz/scratch', 'laszlocsomor/tensorflow', 'Mistobaan/tensorflow', 'Neurita/darwin', 'mariusvniekerk/bayes_logistic', 'adamtiger/tensorflow', 'datachand/h2o-3', 'naoyak/scikit-learn', 'aesuli/scikit-learn', 'mhue/scikit-learn', 'saiwing-yeung/scikit-learn', 'yiyang186/scikit-learn', 'carrillo/scikit-learn', 'IssamLaradji/scikit-learn', 'JT5D/scikit-learn', 'pradyu1993/scikit-learn', 'LohithBlaze/scikit-learn', 'bhargav/scikit-learn', 'JeanKossaifi/scikit-learn', 'PatrickChrist/scikit-learn', 'soulmachine/scikit-learn', 'yask123/scikit-learn', 'russel1237/scikit-learn', 'kmike/scikit-learn', 'krez13/scikit-learn', 'Srisai85/scikit-learn', 'abhishekkrthakur/scikit-learn', 'nelango/ViralityAnalysis', 'Snazz2001/sklearn-pmml', 'bjpcjp/scikit-learn', 'thilbern/scikit-learn', 'maheshakya/scikit-learn', 'f0k/scikit-learn', 'MoamerEncsConcordiaCa/tensorflow', 'karthikrangarajan/intro-to-sklearn', 'danny200309/BuildingMachineLearningSystemsWithPython', 'mrocklin/dasklearn', 'gghatano/scipy_2015_sklearn_tutorial', 'mwleeds/android-malware-analysis', 'osvaldshpengler/BuildingMachineLearningSystemsWithPython', 'tiankanl/sklearn_pycon2015', 'wwf5067/statsmodels', 'huanzhang12/lightgbm-gpu', 'liyi193328/seq2seq', 'alextag/Twitter-Sentiment-Analysis', 'longyangking/ML', 'kpespinosa/BuildingMachineLearningSystemsWithPython', 'yuyuz/FLASH', 'vmo-score/vmo-score', 'gdl-civestav-localization/cinvestav_location_fingerprinting', 'h10r/scikit-learn-template', 'greytip/data-science-utils', 'deaktator/vowpal_wabbit', 'bloody76/pyLDAvis', 'thjashin/tensorflow', 'CurryBoy/ProtoML-Deprecated', 'WojciechMigda/KAGGLE-prudential-life-insurance-assessment', 'jseabold/statsmodels', 'paulstey/boosting', 'classicboyir/BuildingMachineLearningSystemsWithPython', 'xodus7/tensorflow', 'apatti/apatti_ml', 'itdxer/neupy', 'junwucs/h2o-3', 'petewarden/tensorflow_makefile', 'ibab/tensorflow', 'junpenglao/tensorflow', 'mfeurer/HPOlibConfigSpace', 'IlyaGerasimets/h2o-3', 'gtrdp/twitter-clustering', 'Officium/iLearn', 'shishaochen/TensorFlow-0.8-Win', 'mikolajsacha/tweetsclassification', 'guschmue/tensorflow', 'jalexvig/tensorflow', 'spennihana/h2o-3', 'asbhat/ml-notebooks', 'fangtanchen/Learning', 'alvations-all/anythingyouwant', 'francescoinfante/identity', 'cliff007/pattern_classification', 'lukeiwanski/tensorflow-opencl', 'krikru/tensorflow-opencl', 'Tsiems/mobile-sensing-apps', 'zasdfgbnm/tensorflow', 'akionakamura/scikit-learn', 'ViralLeadership/scikit-learn', 'johnowhitaker/bobibabber', 'tbuehler/scikit-learn', 'sinhrks/scikit-learn', 'shazeel1/scikit-learn', 'AIML/scikit-learn', 'YinongLong/scikit-learn', 'evgchz/scikit-learn', 'wavii/scikit-learn', 'ch3ll0v3k/scikit-learn', 'hlin117/scikit-learn', 'themrmax/scikit-learn', 'terkkila/scikit-learn', 'DSLituiev/scikit-learn', 'ngoix/scikit-learn', 'strint/tensorflow', 'macks22/gensim', 'ltiao/scikit-learn', 'plissonf/scikit-learn', '0asa/scikit-learn', 'goswamia/scikit-learn', 'paultheastronomer/OAD-Data-Science-Toolkit', 'Darthone/bug-free-octo-parakeet', 'nanditav/15712-TensorFlow', 'kcompher/sklearn_pycon2015', 'skyduy/simple-dl', 'davidglt/Attractive', 'Matchoc/stockmarketpy', 'clonker/PyEMMA', 'hawk31/pyGPGO', 'karllessard/tensorflow', 'baojianzhou/DLReadingGroup', 'wwunlp/sner', 'jakevdp/sklearn_pycon2014', 'zhaochl/python-utils', 'miaecle/deepchem', 'memo/tensorflow', 'matthewdeanmartin/kata-python', 'jchodera/bhmm', 'kirangonella/BuildingMachineLearningSystemsWithPython', 'lhoang29/vowpal_wabbit', 'vkuznet/rep', 'tgquintela/pythonUtils', 'ChristosChristofidis/h2o-3', 'WaysonKong/blog', 'RapidApplicationDevelopment/tensorflow', 'ikaee/bfr-attendant', 'fmailhot/sklearn-nlp', 'byronyi/tensorflow', 'kiyoto/statsmodels', 'manazhao/tf_recsys', 'bikash/h2o-dev', 'mkomeichi/BuildingMLSystemsWithPython', 'digitalreasoning/vowpal_wabbit', 'martinwicke/tensorflow', 'mrgloom/h2o-3', 'turi-code/SFrame', 'DCSaunders/tensorflow', 'StevenReitsma/gensim-sklearn-wrapper', 'poojavade/Genomics_Docker', 'dylanGeng/BuildingMachineLearningSystemsWithPython', 'verloop/rasa_nlu', 'kemaswill/keras', 'alheinecke/tensorflow-xsmm', 'ProtoML/ProtoML-transforms', 'ternaus/kaggle_otto', 'code-sauce/tensorflow', 'huayue21/pattern_classification', 'sdvillal/manysources', 'aetilley/scikit-learn', 'rth/scikit-learn', 'liyu1990/sklearn', 'joshloyal/scikit-learn', 'jblackburne/scikit-learn', 'equialgo/scikit-learn', 'backyes/scikit-learn', 'dingocuster/scikit-learn', 'kaichogami/scikit-learn', 'rvraghav93/scikit-learn', 'macks22/scikit-learn', 'procoder317/scikit-learn', 'vortex-ape/scikit-learn', 'marcantoinegiuliani/scikit-learn', 'adamgreenhall/scikit-learn', 'IshankGulati/scikit-learn', 'bikong2/scikit-learn', 'RomainBrault/scikit-learn', 'pythonvietnam/scikit-learn', 'SadhanaSrinivasan/scikit-learn', 'ephes/scikit-learn', 'shangwuhencc/scikit-learn', 'alvarofierroclavero/scikit-learn', 'PatrickOReilly/scikit-learn', 'mapto/sprks', 'bowenliu16/deepchem', 'valexandersaulys/prudential_insurance_kaggle', 'laserson/impyla-old', 'nok/sklearn-porter', 'deepchem/deepchem', 'M4573R/BuildingMachineLearningSystemsWithPython', 'lokeshpancharia/BuildingMachineLearningSystemsWithPython', 'sfalkner/pySMAC', 'schottkey7/sklearn_pycon2015', 'jakevdp/sklearn_pydata2015', 'arokem/sklearn-forest-ci', 'samehkamaleldin/pysci-tutorial', 'kreuks/liven', 'dolaameng/keras', 'ralphhaygood/sklearn-gbmi', 'gditzler/eces640-sklearn', 'salma1601/nilearn', 'mathandy/Classifiers2LearnWith', 'mikej888/recipy', 'catalystcomputing/DSIoT-Python-sessions', 'wchan/tensorflow', 'MycChiu/tensorflow', 'yuanchao/pyHiggsML', 'Laurae2/LightGBM', 'tuanvu216/udacity-course', 'vrv/tensorflow', 'h2oai/h2o-dev', 'fsgp/pattern_classification', 'TomAugspurger/statsmodels', 'nishadsingh1/clipper', 'kuza55/keras', 'qiyiping/gbdt', 'lukeiwanski/tensorflow', 'brightchen/h2o-3', 'jamestwhedbee/diogenes', 'sandeepgupta2k4/tensorflow', 'jbedorf/tensorflow', 'danmelamed/vowpal_wabbit', 'chrisspen/sklearn-extra', 'balazssimon/ml-playground', 'rdipietro/tensorflow', 'yarikoptic/pystatsmodels', 'mbillingr/SCoT', 'hsaputra/tensorflow', 'npinto/bangmetric', 'ysasaki6023/NeuralNetworkStudy', 'yl565/statsmodels', 'alekz112/statsmodels', 'whn09/tensorflow', 'Abhijith1995/tumor_classifier', 'xzturn/tensorflow', 'samleoqh/machine-ln', 'dsquareindia/scikit-learn', 'walterreade/scikit-learn', 'ElDeveloper/scikit-learn', 'mjudsp/Tsallis', 'scottclowe/scikit-learn', 'xavierwu/scikit-learn', 'xyguo/scikit-learn', 'sieben/scikit-learn', 'Titan-C/scikit-learn', 'haojunyu/scikit-learn', 'eg-zhang/scikit-learn', 'huzq/scikit-learn', 'kevin-intel/scikit-learn', 'massich/scikit-learn', 'lmcinnes/scikit-learn', 'jmwoloso/scikit-learn', 'qifeigit/scikit-learn', 'murali-munna/scikit-learn', 'stephen-hoover/scikit-learn', 'bigdataelephants/scikit-learn', 'raghavrv/scikit-learn', 'andaag/scikit-learn', 'sshkhrnwbie/scikit-learn', 'Fireblend/scikit-learn', 'altairpearl/scikit-learn', 'absolutelyNoWarranty/scikit-learn', 'cybernet14/scikit-learn', 'HolgerPeters/scikit-learn', 'OshynSong/scikit-learn', 'victorbergelin/scikit-learn', 'sklearn-theano/sklearn-theano', 'NelisVerhoef/scikit-learn', 'kazemakase/scikit-learn', 'superbobry/hyperopt-sklearn', 'psrthegreat/heroku-buildpack-python-sklearn', 'vivekmishra1991/scikit-learn', 'ChanChiChoi/scikit-learn', 'aruneral01/auto-sklearn', 'computational-class/cjc2016', 'dropofwill/author-attr-experiments', 'adamwalz/Jupyter-Notebooks', 'poldracklab/mriqc', 'kamcpp/tensorflow', 'qingkaikong/useful_script', 'eqperes/mvaproject', 'idwaker/sklearn_pydata2015', 'jamessdixon/Kaggle.HomeDepot', 'LevinJ/CodeSamples', 'atulsingh0/MachineLearning', 'AsimmHirani/ISpyPi', 'michalkurka/h2o-3', 'rampasek/seizure-prediction', 'mmadsen/sklearn-mmadsen', 'aboye/changes_to_sklearn_nmf', 'PawarPawan/h2o-v3', 'akshayka/edxclassify', 'UN-DESA-Modelling/Electricity_Consumption_Surveys', 'DavidBrear/sklearn-cookbook', 'vsmolyakov/opt', 'PHLF/rasa_nlu', 'MadsJensen/malthe_alpha_project', 'bhtucker/impyla', 'caisq/tensorflow', 'ericpre/hyperspy', 'aselle/tensorflow', 'ArtsiomCh/tensorflow', 'scenarios/tensorflow', 'Mazecreator/tensorflow', 'ujjwalkarn/DataSciencePython', 'anilmuthineni/tensorflow', 'bospetersen/h2o-3', 'asadziach/tensorflow', 'terrytangyuan/tensorflow', 'ternaus/kaggle_wallmart', 'sssllliang/BuildingMachineLearningSystemsWithPython', 'rasbt/pattern_classification', 'thangluu/pattern_classification', 'jejjohnson/manifold_learning', 'linglaiyao1314/SFrame', 'ppwwyyxx/tensorflow', 'rajegannathan/grasp-lift-eeg-cat-dog-solution-updated', 'phobson/statsmodels', 'petewarden/tensorflow', 'madmax983/h2o-3', 'erh3cq/hyperspy', 'gfgkmn/scikit-learn', 'bpgriner01/scikit-learn', 'bryandeng/scikit-learn', 'mikebenfield/scikit-learn', 'alongwithyou/auto-sklearn', 'scikit-learn/scikit-learn', 'belltailjp/scikit-learn', 'siutanwong/scikit-learn', 'fyffyt/scikit-learn', 'shusenl/scikit-learn', 'jorik041/scikit-learn', 'giorgiop/scikit-learn', 'shenzebang/scikit-learn', 'ZENGXH/scikit-learn', 'arthurmensch/scikit-learn', 'theoryno3/scikit-learn', 'DailyActie/Surrogate-Model', 'asnorkin/sentiment_analysis', 'MohammedWasim/scikit-learn', 'tomMoral/scikit-learn', 'aminert/scikit-learn', 'xzh86/scikit-learn', 'pratapvardhan/scikit-learn', 'jkarnows/scikit-learn', 'dhruv13J/scikit-learn', 'loli/sklearn-ensembletrees', 'pv/scikit-learn', 'banilo/scikit-learn', 'rsivapr/scikit-learn', 'cl4rke/scikit-learn', 'costypetrisor/scikit-learn', 'ankurankan/scikit-learn', 'r-mart/scikit-learn', 'hugobowne/scikit-learn', 'rasbt/scikit-learn', 'bjkomer/hyperopt-sklearn', 'wolverton-research-group/qmpy', 'ericmjl/scikit-learn-tutorial', 'statsmodels/statsmodels', 'yosssi/scipy_2015_sklearn_tutorial', 'JoshuaMichaelKing/MyLearning', 'samstav/scipy_2015_sklearn_tutorial', 'Jeff20/scipy_2015_sklearn_tutorial', 'zycdragonball/tensorflow', 'jskDr/jamespy_py3', 'xiaoyuge16/flasklearn', 'erp12/pyshgp', 'raosudha89/vowpal_wabbit', 'jcrudy/glm-sklearn', 'marionleborgne/nupic.research', 'computational-class/computational-communication-2016', 'sangwook236/SWDT', 'yuncliu/Learn', 'bzamecnik/tfr', 'srndic/mimicus', 'yuantw/MachineLearning', 'mariusvniekerk/impyla', 'andrecosta90/sklearn-autoencoder', 'DeepGnosis/keras', 'mpearmain/BayesBoost', 'tperol/earthquake-clusters', 'Denisolt/Tensorflow_Chat_Bot', 'anaguma2261/scikit-learn-sample', 'VisTrails/VisTrails', 'mndrake/h2o-3', 'DonBeo/statsmodels', 'ninotoshi/tensorflow', 'pierreg/tensorflow', 'plowman/python-mcparseface', 'tensorflow/tensorflow', 'mdrumond/tensorflow', 'marko-asplund/vowpal_wabbit', 'softwaremechanic/Miscellaneous', 'chrissly31415/amimanera', 'vinay631/h2o-3', 'sato9hara/defragTrees', 'musically-ut/statsmodels', 'ppries/tensorflow', 'naturali/tensorflow', 'turiphro/deeplearning', 'sem-geologist/hyperspy', 'av8ramit/tensorflow', 'xunilrj/sandbox', 'JonasWallin/BayesFlow', 'vidartf/hyperspy', 'rew4332/tensorflow', 'LiaoPan/scikit-learn', 'PrashntS/scikit-learn', 'potash/scikit-learn', 'JsNoNo/scikit-learn', 'antoinecarme/sklearn2sql_heroku', 'CVML/scikit-learn', 'Adai0808/scikit-learn', 'mkrump/scikit-learn', 'ivannz/scikit-learn', 'mblondel/scikit-learn', 'neale/CS-program', 'fengzhyuan/scikit-learn', 'glouppe/scikit-learn', 'h2educ/scikit-learn', 'mattilyra/scikit-learn', 'madjelan/scikit-learn', 'eickenberg/scikit-learn', 'nrhine1/scikit-learn', 'Hongyan0627/scikit-learn', 'liangz0707/scikit-learn', 'kwailamchan/programming-languages', 'mlyundin/Machine-Learning', 'sebp/scikit-learn-mpi-grid-search', 'jljones/sklearn_pycon2014', 'cameronlai/ml-class-python', 'maciekcc/tensorflow', 'flennerhag/mlens', 'apark263/tensorflow', 'martinggww/lucasenlights', 'peastman/deepchem', 'sugartom/tensorflow-alien', 'bradmontgomery/ml', 'Og192/Python', 'numenta/nupic.research', 'jasonleaster/Machine_Learning', 'scikit-learn-contrib/hdbscan', 'automl/pysmac', 'duyet-website/api.duyet.net', 'subutai/htmresearch', 'erichseamon/sklearn_pycon2015', 'jannson/Similar', 'jpzk/evopy', 'asimshankar/tensorflow', 'LiaoPan/sklearn_pycon2015', 'GateNLP/sklearn-wrapper', 'cancan101/tensorflow', 'omangin/multimodal', 'mhdella/pattern_classification', 'laosiaudi/tensorflow', 'asteryx/accounting', 'MechCoder/GlmnetvsSklearn', 'fstonezst/LightGBM', 'jubatus/jubakit', 'dendisuhubdy/tensorflow', 'xiaoganghan/sklearn-progressbar-cm', 'juharris/tensorflow', 'kshimasaki/ML-fMRI-Pipeline', 'wangyum/tensorflow', 'rasbt/bugreport', 'alshedivat/tensorflow', 'dyoung418/tensorflow', 'CKboss/TheBauble', 'thomas-bottesch/fcl', 'scikit-learn/sklearn-docbuilder', 'astroML/sklearn_tutorial', 'zuku1985/scikit-learn', 'mwv/scikit-learn', 'aabadie/scikit-learn', 'khkaminska/scikit-learn', 'ycaihua/scikit-learn', 'michigraber/scikit-learn', 'ishank08/scikit-learn', 'jpautom/scikit-learn', 'yunfeilu/scikit-learn', 'tkamishima/forked-scikit-learn', 'ssaeger/scikit-learn', 'B3AU/waveTree', 'zyxue/scikit-learn', 'HeraclesHX/scikit-learn', 'yaoli/sklearn-theano', 'shahankhatch/scikit-learn', 'zaxtax/scikit-learn', 'mojoboss/scikit-learn', 'RPGOne/scikit-learn', 'pompiduskus/scikit-learn', 'yonglehou/scikit-learn', 'scr4t/BayesianOptimization', 'soerendip42/scikit-learn', 'RayMick/scikit-learn', 'mayblue9/scikit-learn', 'rohit12/scikit-learn', 'cheesinglee/random_forest_compare', 'paultopia/auto-sklearn', 'yandex/rep', 'wxchan/LightGBM', 'KellyChan/python-examples', 'pcm17/tensorflow', 'peterbraden/tensorflow', 'raincoatrun/sklearn_tutorial', 'jakevdp/sklearn_tutorial', 'agomariz/scikit-neuralnetwork', 'robbisg/mvpa_itab_wu', 'kchodorow/tensorflow', 'nebw/keras', 'nuffe/flake8-sklearn-rcheck', 'Kitware/SMQTK', 'shiyemin/tensorflow', 'wiki-ai/revscoring', 'quole/gensim', 'thomasaarholt/hyperspy', 'fmv1992/data_utilities', 'mrcslws/nupic.research', 'alcmrt/Machine-Learning', 'weaver-viii/h2o-3', 'summerAI/serapis', 'cbmoore/statsmodels', 'chenjun0210/tensorflow', 'gef756/statsmodels', 'tricao/vowpal_wabbit', 'codez266/revscoring', 'neurospin/pylearn-epac', 'kevin-coder/tensorflow-fork', 'hainm/statsmodels', 'recursix/spearmint-salad', 'Averroes/statsmodels', 'haeusser/tensorflow', 'rth/FreeDiscovery', 'chemelnucfin/tensorflow', 'ViralLeadership/statsmodels', 'kazarinov/hccf', 'markslwong/tensorflow', 'ageron/tensorflow', '3ll3d00d/vibe', 'thesuperzapper/tensorflow', 'anand-c-goog/tensorflow', 'aldro61/pyscm', 'LUTAN/tensorflow', 'jskDr/jamespy', 'to266/hyperspy', 'lukas/ml-class', 'arborh/tensorflow', 'jeffzheng1/tensorflow', 'manjunaths/tensorflow', 'all-umass/metric-learn', 'PierreBdR/statsmodels', 'shakamunyi/tensorflow', 'amueller/scikit-learn', 'dohmatob/scikit-learn', 'jayflo/scikit-learn', 'ndingwall/scikit-learn', 'MatthieuBizien/scikit-learn', 'sonnyhu/scikit-learn', 'vighneshbirodkar/scikit-learn', 'AlexandreAbraham/scikit-learn', 'bthirion/scikit-learn', 'xiruizhifu/scikit-learn', 'anntzer/scikit-learn', 'heli522/scikit-learn', 'davidgbe/scikit-learn', 'kylerbrown/scikit-learn', 'aewhatley/scikit-learn', 'Lawrence-Liu/scikit-learn', 'lucasdavid/scikit-learn', 'henridwyer/scikit-learn', 'ishanic/scikit-learn', 'cython-testbed/scikit-learn', 'billy-inn/scikit-learn', 'IndraVikas/scikit-learn', 'GaelVaroquaux/scikit-learn', 'manashmndl/scikit-learn', 'wzbozon/scikit-learn', 'aniryou/scikit-learn', 'meduz/scikit-learn', 'vigilv/scikit-learn', 'rubikloud/scikit-learn', 'cwu2011/scikit-learn', 'tawsifkhan/scikit-learn', 'elijah513/scikit-learn', 'henrykironde/scikit-learn', 'rexshihaoren/scikit-learn', 'q1ang/scikit-learn', 'Clyde-fare/scikit-learn', 'grisaitis/sklearn-pmml', 'christyheaton/scikit-learn', 'maxlikely/scikit-learn', 'sigopt/sigopt_sklearn', 'appapantula/scikit-learn', 'jlegendary/scikit-learn', 'alex-pirozhenko/sklearn-pmml', 'shikhardb/scikit-learn', 'eickenberg/sklearn-theano', 'zhmz90/first_step_with_julia_kaggle.jl', 'KellyChan/Python', 'Darthone/Informed-Finance-Canary', 'rbharath/deepchem', 'aelaguiz/pyvotune', 'sjchakrav/pattern_classification', 'Kreiswolke/gensim', 'rosenbrockc/acorn', 'wavelets/scipy_2015_sklearn_tutorial', 'mouradmourafiq/pandas2sklearn', 'hyperopt/hyperopt-sklearn', 'SquirrelMajik/GRec', 'zinderud/ysa', 'zachmayer/vowpal_wabbit', 'aruneral01/autokit', 'alepulver/tp-final-incc', 'yarikoptic/vowpal_wabbit', 'yaojenkuo/BuildingMachineLearningSystemsWithPython', 'isabellewei/deephealth', 'paolodedios/tensorflow', 'patemotter/trilinos-prediction', 'rishirajsurti/BuildingMachineLearningSystemsWithPython', 'Bismarrck/tensorflow', 'AleZandona/INF', 'dimroc/tensorflow-mnist-tutorial', 'bowang/tensorflow', 'aigamedev/scikit-neuralnetwork', 'johndpope/tensorflow', 'srp33/ShinyLearner', 'markgw/pimlico', 'thirdwing/SFrame', 'siddharthhparikh/INFM750-project', 'TakayukiSakai/tensorflow', 'tangsttw/python-machine-learning-practice', 'jhaux/tensorflow', 'LevinJ/SSD_tensorflow_VOC', 'LevinJ/Supply-demand-forecasting', 'alexst07/MachineLearning', 'jasonyaw/SFrame', 'IndraVikas/scikit-neuralnetwork', 'dcrankshaw/clipper', 'taylorwood/Kaggle.HomeDepot', 'clintpgeorge/gaur', 'mpearmain/gestalt', 'gmtahackers/deeplearning']\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\\\n",
    "SELECT\n",
    "    DISTINCT(repo_name)\n",
    "FROM\n",
    "    `Odyssey_github_sklearn.content_py_full` \n",
    "WHERE\n",
    "    (REGEXP_CONTAINS(path,\"sklearn\")) OR\n",
    "    (REGEXP_CONTAINS(repo_name,\"scikit-learn\")) OR\n",
    "    (REGEXP_CONTAINS(repo_name,\"sklearn\")) OR\n",
    "    (REGEXP_CONTAINS(path,\"scikit-learn\"))\n",
    "\"\"\"\n",
    "gp = GithubPython()\n",
    "\n",
    "\n",
    "\n",
    "excludedRepos = [repo_name[0] for repo_name in gp.run(query, project=\"odyssey-193217\")]\n",
    "print(excludedRepos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def excludeByRepoFull(excludeByRepos):\n",
    "    if not excludedRepos:\n",
    "        return \"\"\n",
    "    s = '(NOT REGEXP_CONTAINS(repo_name,\"%s\"))' % excludedRepos[0]\n",
    "    for repo in excludedRepos[1:]:\n",
    "        s += ' AND '\n",
    "        s += '(NOT REGEXP_CONTAINS(repo_name,\"%s\"))' % repo\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SklearnMultipleLibraries= []\n",
    "\n",
    "for moduleName in otherModuleList:\n",
    "\n",
    "    sklearnWithOtherModulesQuery = \"\"\"\\\n",
    "    SELECT repo_name, COUNT(*) count\n",
    "    FROM\n",
    "          `Odyssey_github_sklearn.content_py_full`\n",
    "          \n",
    "\n",
    "          WHERE ((REGEXP_CONTAINS(content, 'sklearn')) AND\n",
    "          (REGEXP_CONTAINS(content, '%s'))) AND  (%s)\n",
    "          \n",
    "          \n",
    "    GROUP BY 1\n",
    "    ORDER BY count DESC\n",
    "    \"\"\" %(moduleName, excludeByRepoFull(excludedRepos))\n",
    "    \n",
    "    \n",
    "    sklearnWithOtherModules = gp.run(sklearnWithOtherModulesQuery)\n",
    "    \n",
    "    SklearnMultipleLibraries.append(sklearnWithOtherModules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10563</th>\n",
       "      <th>10564</th>\n",
       "      <th>10565</th>\n",
       "      <th>10566</th>\n",
       "      <th>10567</th>\n",
       "      <th>10568</th>\n",
       "      <th>10569</th>\n",
       "      <th>10570</th>\n",
       "      <th>10571</th>\n",
       "      <th>10572</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(bottydim/detect-credit-card-fraud, 8)</td>\n",
       "      <td>(korin-worm-code/LevelJoiner, 5)</td>\n",
       "      <td>(apapiu/airbnb_app, 4)</td>\n",
       "      <td>(datamindedbe/train-occupancy, 4)</td>\n",
       "      <td>(Aurora0001/LearnProgrammingBot, 4)</td>\n",
       "      <td>(bhzunami/Immo, 3)</td>\n",
       "      <td>(joshpeng/Network-Intrusions-Flask, 3)</td>\n",
       "      <td>(antoinecarme/pyaf, 3)</td>\n",
       "      <td>(reiinakano/xcessiv, 3)</td>\n",
       "      <td>(mdeff/ntds_2016, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(KennyCandy/HAR, 74)</td>\n",
       "      <td>(mne-tools/mne-tools.github.io, 72)</td>\n",
       "      <td>(zooniverse/aggregation, 65)</td>\n",
       "      <td>(bsipocz/astroML, 50)</td>\n",
       "      <td>(kcavagnolo/astroML, 50)</td>\n",
       "      <td>(nhuntwalker/astroML, 50)</td>\n",
       "      <td>(eramirem/astroML, 50)</td>\n",
       "      <td>(leofdecarvalho/MachineLearning, 44)</td>\n",
       "      <td>(Haunter17/MIR_SU17, 41)</td>\n",
       "      <td>(thast/EOSC513, 36)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(magic2du/contact_matrix, 80)</td>\n",
       "      <td>(pandas-ml/pandas-ml, 74)</td>\n",
       "      <td>(sinhrks/pandas-ml, 74)</td>\n",
       "      <td>(MadsJensen/dbs_pd, 60)</td>\n",
       "      <td>(Tjorriemorrie/trading, 51)</td>\n",
       "      <td>(paulperry/kaggle, 50)</td>\n",
       "      <td>(Karl-Marka/data-mining, 45)</td>\n",
       "      <td>(leofdecarvalho/MachineLearning, 44)</td>\n",
       "      <td>(thast/EOSC513, 36)</td>\n",
       "      <td>(parekhmitchell/Machine-Learning, 36)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(rohit21122012/DCASE2013, 145)</td>\n",
       "      <td>(magic2du/contact_matrix, 103)</td>\n",
       "      <td>(KennyCandy/HAR, 74)</td>\n",
       "      <td>(mne-tools/mne-tools.github.io, 73)</td>\n",
       "      <td>(zooniverse/aggregation, 71)</td>\n",
       "      <td>(MadsJensen/dbs_pd, 66)</td>\n",
       "      <td>(chkoar/imbalanced-learn, 60)</td>\n",
       "      <td>(glemaitre/imbalanced-learn, 60)</td>\n",
       "      <td>(bsipocz/astroML, 59)</td>\n",
       "      <td>(eramirem/astroML, 59)</td>\n",
       "      <td>...</td>\n",
       "      <td>(vjlbym/sima, 1)</td>\n",
       "      <td>(johnthebrave/sentiment-mining, 1)</td>\n",
       "      <td>(discourse-lab/DiscourseSegmenter, 1)</td>\n",
       "      <td>(rasmunk/set11521cw2, 1)</td>\n",
       "      <td>(gifford-lab/CpGenie, 1)</td>\n",
       "      <td>(braingineer/pyromancy, 1)</td>\n",
       "      <td>(ctb/cvxpy, 1)</td>\n",
       "      <td>(pprett/statsmodels, 1)</td>\n",
       "      <td>(ctSkennerton/CompareM, 1)</td>\n",
       "      <td>(shawngraham/SOMPY, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(magic2du/contact_matrix, 59)</td>\n",
       "      <td>(diogo149/treeano, 43)</td>\n",
       "      <td>(mengyun1993/RNN-binary, 33)</td>\n",
       "      <td>(jagill/treeano, 32)</td>\n",
       "      <td>(nsauder/treeano, 26)</td>\n",
       "      <td>(artmusic0/theano-learning.part03, 20)</td>\n",
       "      <td>(davidvartanian/machine-learning-tests, 16)</td>\n",
       "      <td>(jvpoulos/cs289-project, 16)</td>\n",
       "      <td>(artmusic0/theano-learning.part02, 14)</td>\n",
       "      <td>(abhishekkrthakur/NDSB, 13)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(bromjiri/Presto, 20)</td>\n",
       "      <td>(gtesei/fast-furious, 19)</td>\n",
       "      <td>(totuta/deep-supertagging, 17)</td>\n",
       "      <td>(tanayz/Kaggle, 17)</td>\n",
       "      <td>(canast02/csci544_fall2016_project, 14)</td>\n",
       "      <td>(mramire8/active, 13)</td>\n",
       "      <td>(ProjectsUCSC/NLP, 11)</td>\n",
       "      <td>(SingaporeNews/singaporenews.github.io, 10)</td>\n",
       "      <td>(manankalra/Twitter-Sentiment-Analysis, 10)</td>\n",
       "      <td>(vinhqdang/wikipedia_analysis, 10)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(KennyCandy/HAR, 74)</td>\n",
       "      <td>(Haunter17/MIR_SU17, 43)</td>\n",
       "      <td>(fluxcapacitor/education.ml, 34)</td>\n",
       "      <td>(panmari/tensorflow, 34)</td>\n",
       "      <td>(awni/tensorflow, 34)</td>\n",
       "      <td>(marmarko/ml101, 25)</td>\n",
       "      <td>(ElvisLouis/code, 24)</td>\n",
       "      <td>(dansbecker/skflow, 23)</td>\n",
       "      <td>(dricciardelli/vae2vec, 18)</td>\n",
       "      <td>(derrowap/MA490-MachineLearning-FinalProject, 18)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(JazzeYoung/VeryDeepAutoEncoder, 22)</td>\n",
       "      <td>(mclaughlin6464/pylearn2, 14)</td>\n",
       "      <td>(CIFASIS/pylearn2, 12)</td>\n",
       "      <td>(TNick/pylearn2, 11)</td>\n",
       "      <td>(daemonmaker/pylearn2, 11)</td>\n",
       "      <td>(jamessergeant/pylearn2, 11)</td>\n",
       "      <td>(cosmoharrigan/pylearn2, 11)</td>\n",
       "      <td>(hantek/pylearn2, 11)</td>\n",
       "      <td>(nouiz/pylearn2, 11)</td>\n",
       "      <td>(lisa-lab/pylearn2, 11)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(synbiochem/synbiochem-learn, 4)</td>\n",
       "      <td>(neilswainston/synbiochem-learn, 4)</td>\n",
       "      <td>(mayou36/raredecay, 3)</td>\n",
       "      <td>(neilswainston/development-py, 2)</td>\n",
       "      <td>(bzamecnik/ml-playground, 2)</td>\n",
       "      <td>(mayavanand/RMMAFinalProject, 2)</td>\n",
       "      <td>(bzamecnik/audio-ml, 2)</td>\n",
       "      <td>(bzamecnik/ml, 2)</td>\n",
       "      <td>(mwalton/artificial-olfaction, 2)</td>\n",
       "      <td>(pablocarderam/genetargeter, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(guyrose3/fast-rcnn, 5)</td>\n",
       "      <td>(skyfallen/Kaggle-Diabetic-Retinopathy-Detecti...</td>\n",
       "      <td>(yassersouri/omgh, 5)</td>\n",
       "      <td>(IdiosyncraticDragon/relief_rcnn, 4)</td>\n",
       "      <td>(philo-zhang/cnn-tracker, 4)</td>\n",
       "      <td>(SelinaChe/Complex-Object-Detection-StackGAN, 4)</td>\n",
       "      <td>(gnina/scripts, 4)</td>\n",
       "      <td>(luhaofang/tripletloss, 3)</td>\n",
       "      <td>(HaydenFaulkner/phd, 3)</td>\n",
       "      <td>(axel-angel/master-project, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(muthujothi/Kaggle-schizophrenia-classificatio...</td>\n",
       "      <td>(clclcocoro/MLwithGA, 3)</td>\n",
       "      <td>(samshara/Stock-Market-Analysis-and-Prediction...</td>\n",
       "      <td>(bingo5/FundForecast, 2)</td>\n",
       "      <td>(igorpejic/pytrader, 2)</td>\n",
       "      <td>(owocki/pytrader, 2)</td>\n",
       "      <td>(ccf/pytrader, 2)</td>\n",
       "      <td>(bavent/Space-Weather-Forecasting, 2)</td>\n",
       "      <td>(Collumbus/ann_xor, 2)</td>\n",
       "      <td>(ecodan/kaggle-connectomix, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(datasciencebr/serenata-de-amor, 1)</td>\n",
       "      <td>(lanceculnane/electricity-conservation, 1)</td>\n",
       "      <td>(marcusrehm/serenata-de-amor, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(automl/ChaLearn_Automatic_Machine_Learning_Ch...</td>\n",
       "      <td>(lbarnett/BirdID, 7)</td>\n",
       "      <td>(md100play/BirdID, 5)</td>\n",
       "      <td>(rgtjf/Semantic-Texual-Similarity-Toolkits, 5)</td>\n",
       "      <td>(tmills/uda, 5)</td>\n",
       "      <td>(jimmycallin/master-thesis, 5)</td>\n",
       "      <td>(tmills/neural-assertion, 5)</td>\n",
       "      <td>(MadsJensen/dbs_pd, 5)</td>\n",
       "      <td>(yashchandak/GNN, 4)</td>\n",
       "      <td>(linbojin/dv4sa, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(jimmycallin/master-thesis, 10)</td>\n",
       "      <td>(OHDSI/PatientLevelPrediction, 6)</td>\n",
       "      <td>(Hi-king/scikitcl, 5)</td>\n",
       "      <td>(feuerchop/increOCSVM, 4)</td>\n",
       "      <td>(vespero89/Snoring_Challenge, 4)</td>\n",
       "      <td>(ernfrid/skll, 4)</td>\n",
       "      <td>(jbaker92/logistic_control_variate, 3)</td>\n",
       "      <td>(wattlebird/pystruct, 3)</td>\n",
       "      <td>(RomainBrault/operalib, 3)</td>\n",
       "      <td>(pystruct/pystruct, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(cognoma/machine-learning, 18)</td>\n",
       "      <td>(acimmarusti/isl_exercises, 14)</td>\n",
       "      <td>(samuelefiorini/cgm-tools, 8)</td>\n",
       "      <td>(JudoWill/ResearchNotebooks, 7)</td>\n",
       "      <td>(pranavtbhat/EE219, 6)</td>\n",
       "      <td>(DonghoChoi/Exploration_Study, 6)</td>\n",
       "      <td>(rafaelgiordano12/evolvings, 6)</td>\n",
       "      <td>(jchodera/LiquidBenchmark, 5)</td>\n",
       "      <td>(dlatk/dlatk, 5)</td>\n",
       "      <td>(tgsmith61591/pyramid, 5)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(magic2du/contact_matrix, 103)</td>\n",
       "      <td>(TinyOS-Camp/DDEA-DEV, 49)</td>\n",
       "      <td>(diogo149/CauseEffectPairsPaper, 41)</td>\n",
       "      <td>(tedmeeds/tcga_encoder, 40)</td>\n",
       "      <td>(thast/EOSC513, 36)</td>\n",
       "      <td>(JosmanPS/parallel-SVM, 34)</td>\n",
       "      <td>(jundongl/scikit-feature, 29)</td>\n",
       "      <td>(jundongl/scikit-feast, 29)</td>\n",
       "      <td>(jundongl/PyFeaST, 29)</td>\n",
       "      <td>(annapasca/mne-python, 26)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 10573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0      \\\n",
       "0              (bottydim/detect-credit-card-fraud, 8)   \n",
       "1                                (KennyCandy/HAR, 74)   \n",
       "2                       (magic2du/contact_matrix, 80)   \n",
       "3                      (rohit21122012/DCASE2013, 145)   \n",
       "4                       (magic2du/contact_matrix, 59)   \n",
       "5                               (bromjiri/Presto, 20)   \n",
       "6                                (KennyCandy/HAR, 74)   \n",
       "7                (JazzeYoung/VeryDeepAutoEncoder, 22)   \n",
       "8                    (synbiochem/synbiochem-learn, 4)   \n",
       "9                                                None   \n",
       "10                            (guyrose3/fast-rcnn, 5)   \n",
       "11  (muthujothi/Kaggle-schizophrenia-classificatio...   \n",
       "12                (datasciencebr/serenata-de-amor, 1)   \n",
       "13  (automl/ChaLearn_Automatic_Machine_Learning_Ch...   \n",
       "14                    (jimmycallin/master-thesis, 10)   \n",
       "15                     (cognoma/machine-learning, 18)   \n",
       "16                     (magic2du/contact_matrix, 103)   \n",
       "\n",
       "                                                1      \\\n",
       "0                    (korin-worm-code/LevelJoiner, 5)   \n",
       "1                 (mne-tools/mne-tools.github.io, 72)   \n",
       "2                           (pandas-ml/pandas-ml, 74)   \n",
       "3                      (magic2du/contact_matrix, 103)   \n",
       "4                              (diogo149/treeano, 43)   \n",
       "5                           (gtesei/fast-furious, 19)   \n",
       "6                            (Haunter17/MIR_SU17, 43)   \n",
       "7                       (mclaughlin6464/pylearn2, 14)   \n",
       "8                 (neilswainston/synbiochem-learn, 4)   \n",
       "9                                                None   \n",
       "10  (skyfallen/Kaggle-Diabetic-Retinopathy-Detecti...   \n",
       "11                           (clclcocoro/MLwithGA, 3)   \n",
       "12         (lanceculnane/electricity-conservation, 1)   \n",
       "13                               (lbarnett/BirdID, 7)   \n",
       "14                  (OHDSI/PatientLevelPrediction, 6)   \n",
       "15                    (acimmarusti/isl_exercises, 14)   \n",
       "16                         (TinyOS-Camp/DDEA-DEV, 49)   \n",
       "\n",
       "                                                2      \\\n",
       "0                              (apapiu/airbnb_app, 4)   \n",
       "1                        (zooniverse/aggregation, 65)   \n",
       "2                             (sinhrks/pandas-ml, 74)   \n",
       "3                                (KennyCandy/HAR, 74)   \n",
       "4                        (mengyun1993/RNN-binary, 33)   \n",
       "5                      (totuta/deep-supertagging, 17)   \n",
       "6                    (fluxcapacitor/education.ml, 34)   \n",
       "7                              (CIFASIS/pylearn2, 12)   \n",
       "8                              (mayou36/raredecay, 3)   \n",
       "9                                                None   \n",
       "10                              (yassersouri/omgh, 5)   \n",
       "11  (samshara/Stock-Market-Analysis-and-Prediction...   \n",
       "12                   (marcusrehm/serenata-de-amor, 1)   \n",
       "13                              (md100play/BirdID, 5)   \n",
       "14                              (Hi-king/scikitcl, 5)   \n",
       "15                      (samuelefiorini/cgm-tools, 8)   \n",
       "16               (diogo149/CauseEffectPairsPaper, 41)   \n",
       "\n",
       "                                             3      \\\n",
       "0                (datamindedbe/train-occupancy, 4)   \n",
       "1                            (bsipocz/astroML, 50)   \n",
       "2                          (MadsJensen/dbs_pd, 60)   \n",
       "3              (mne-tools/mne-tools.github.io, 73)   \n",
       "4                             (jagill/treeano, 32)   \n",
       "5                              (tanayz/Kaggle, 17)   \n",
       "6                         (panmari/tensorflow, 34)   \n",
       "7                             (TNick/pylearn2, 11)   \n",
       "8                (neilswainston/development-py, 2)   \n",
       "9                                             None   \n",
       "10            (IdiosyncraticDragon/relief_rcnn, 4)   \n",
       "11                        (bingo5/FundForecast, 2)   \n",
       "12                                            None   \n",
       "13  (rgtjf/Semantic-Texual-Similarity-Toolkits, 5)   \n",
       "14                       (feuerchop/increOCSVM, 4)   \n",
       "15                 (JudoWill/ResearchNotebooks, 7)   \n",
       "16                     (tedmeeds/tcga_encoder, 40)   \n",
       "\n",
       "                                      4      \\\n",
       "0       (Aurora0001/LearnProgrammingBot, 4)   \n",
       "1                  (kcavagnolo/astroML, 50)   \n",
       "2               (Tjorriemorrie/trading, 51)   \n",
       "3              (zooniverse/aggregation, 71)   \n",
       "4                     (nsauder/treeano, 26)   \n",
       "5   (canast02/csci544_fall2016_project, 14)   \n",
       "6                     (awni/tensorflow, 34)   \n",
       "7                (daemonmaker/pylearn2, 11)   \n",
       "8              (bzamecnik/ml-playground, 2)   \n",
       "9                                      None   \n",
       "10             (philo-zhang/cnn-tracker, 4)   \n",
       "11                  (igorpejic/pytrader, 2)   \n",
       "12                                     None   \n",
       "13                          (tmills/uda, 5)   \n",
       "14         (vespero89/Snoring_Challenge, 4)   \n",
       "15                   (pranavtbhat/EE219, 6)   \n",
       "16                      (thast/EOSC513, 36)   \n",
       "\n",
       "                                               5      \\\n",
       "0                                 (bhzunami/Immo, 3)   \n",
       "1                          (nhuntwalker/astroML, 50)   \n",
       "2                             (paulperry/kaggle, 50)   \n",
       "3                            (MadsJensen/dbs_pd, 66)   \n",
       "4             (artmusic0/theano-learning.part03, 20)   \n",
       "5                              (mramire8/active, 13)   \n",
       "6                               (marmarko/ml101, 25)   \n",
       "7                       (jamessergeant/pylearn2, 11)   \n",
       "8                   (mayavanand/RMMAFinalProject, 2)   \n",
       "9                                               None   \n",
       "10  (SelinaChe/Complex-Object-Detection-StackGAN, 4)   \n",
       "11                              (owocki/pytrader, 2)   \n",
       "12                                              None   \n",
       "13                    (jimmycallin/master-thesis, 5)   \n",
       "14                                 (ernfrid/skll, 4)   \n",
       "15                 (DonghoChoi/Exploration_Study, 6)   \n",
       "16                       (JosmanPS/parallel-SVM, 34)   \n",
       "\n",
       "                                          6      \\\n",
       "0        (joshpeng/Network-Intrusions-Flask, 3)   \n",
       "1                        (eramirem/astroML, 50)   \n",
       "2                  (Karl-Marka/data-mining, 45)   \n",
       "3                 (chkoar/imbalanced-learn, 60)   \n",
       "4   (davidvartanian/machine-learning-tests, 16)   \n",
       "5                        (ProjectsUCSC/NLP, 11)   \n",
       "6                         (ElvisLouis/code, 24)   \n",
       "7                  (cosmoharrigan/pylearn2, 11)   \n",
       "8                       (bzamecnik/audio-ml, 2)   \n",
       "9                                          None   \n",
       "10                           (gnina/scripts, 4)   \n",
       "11                            (ccf/pytrader, 2)   \n",
       "12                                         None   \n",
       "13                 (tmills/neural-assertion, 5)   \n",
       "14       (jbaker92/logistic_control_variate, 3)   \n",
       "15              (rafaelgiordano12/evolvings, 6)   \n",
       "16                (jundongl/scikit-feature, 29)   \n",
       "\n",
       "                                          7      \\\n",
       "0                        (antoinecarme/pyaf, 3)   \n",
       "1          (leofdecarvalho/MachineLearning, 44)   \n",
       "2          (leofdecarvalho/MachineLearning, 44)   \n",
       "3              (glemaitre/imbalanced-learn, 60)   \n",
       "4                  (jvpoulos/cs289-project, 16)   \n",
       "5   (SingaporeNews/singaporenews.github.io, 10)   \n",
       "6                       (dansbecker/skflow, 23)   \n",
       "7                         (hantek/pylearn2, 11)   \n",
       "8                             (bzamecnik/ml, 2)   \n",
       "9                                          None   \n",
       "10                   (luhaofang/tripletloss, 3)   \n",
       "11        (bavent/Space-Weather-Forecasting, 2)   \n",
       "12                                         None   \n",
       "13                       (MadsJensen/dbs_pd, 5)   \n",
       "14                     (wattlebird/pystruct, 3)   \n",
       "15                (jchodera/LiquidBenchmark, 5)   \n",
       "16                  (jundongl/scikit-feast, 29)   \n",
       "\n",
       "                                          8      \\\n",
       "0                       (reiinakano/xcessiv, 3)   \n",
       "1                      (Haunter17/MIR_SU17, 41)   \n",
       "2                           (thast/EOSC513, 36)   \n",
       "3                         (bsipocz/astroML, 59)   \n",
       "4        (artmusic0/theano-learning.part02, 14)   \n",
       "5   (manankalra/Twitter-Sentiment-Analysis, 10)   \n",
       "6                   (dricciardelli/vae2vec, 18)   \n",
       "7                          (nouiz/pylearn2, 11)   \n",
       "8             (mwalton/artificial-olfaction, 2)   \n",
       "9                                          None   \n",
       "10                      (HaydenFaulkner/phd, 3)   \n",
       "11                       (Collumbus/ann_xor, 2)   \n",
       "12                                         None   \n",
       "13                         (yashchandak/GNN, 4)   \n",
       "14                   (RomainBrault/operalib, 3)   \n",
       "15                             (dlatk/dlatk, 5)   \n",
       "16                       (jundongl/PyFeaST, 29)   \n",
       "\n",
       "                                                9               ...            \\\n",
       "0                                (mdeff/ntds_2016, 2)           ...             \n",
       "1                                 (thast/EOSC513, 36)           ...             \n",
       "2               (parekhmitchell/Machine-Learning, 36)           ...             \n",
       "3                              (eramirem/astroML, 59)           ...             \n",
       "4                         (abhishekkrthakur/NDSB, 13)           ...             \n",
       "5                  (vinhqdang/wikipedia_analysis, 10)           ...             \n",
       "6   (derrowap/MA490-MachineLearning-FinalProject, 18)           ...             \n",
       "7                             (lisa-lab/pylearn2, 11)           ...             \n",
       "8                     (pablocarderam/genetargeter, 2)           ...             \n",
       "9                                                None           ...             \n",
       "10                     (axel-angel/master-project, 3)           ...             \n",
       "11                     (ecodan/kaggle-connectomix, 2)           ...             \n",
       "12                                               None           ...             \n",
       "13                                (linbojin/dv4sa, 2)           ...             \n",
       "14                             (pystruct/pystruct, 3)           ...             \n",
       "15                          (tgsmith61591/pyramid, 5)           ...             \n",
       "16                         (annapasca/mne-python, 26)           ...             \n",
       "\n",
       "               10563                               10564  \\\n",
       "0               None                                None   \n",
       "1               None                                None   \n",
       "2               None                                None   \n",
       "3   (vjlbym/sima, 1)  (johnthebrave/sentiment-mining, 1)   \n",
       "4               None                                None   \n",
       "5               None                                None   \n",
       "6               None                                None   \n",
       "7               None                                None   \n",
       "8               None                                None   \n",
       "9               None                                None   \n",
       "10              None                                None   \n",
       "11              None                                None   \n",
       "12              None                                None   \n",
       "13              None                                None   \n",
       "14              None                                None   \n",
       "15              None                                None   \n",
       "16              None                                None   \n",
       "\n",
       "                                    10565                     10566  \\\n",
       "0                                    None                      None   \n",
       "1                                    None                      None   \n",
       "2                                    None                      None   \n",
       "3   (discourse-lab/DiscourseSegmenter, 1)  (rasmunk/set11521cw2, 1)   \n",
       "4                                    None                      None   \n",
       "5                                    None                      None   \n",
       "6                                    None                      None   \n",
       "7                                    None                      None   \n",
       "8                                    None                      None   \n",
       "9                                    None                      None   \n",
       "10                                   None                      None   \n",
       "11                                   None                      None   \n",
       "12                                   None                      None   \n",
       "13                                   None                      None   \n",
       "14                                   None                      None   \n",
       "15                                   None                      None   \n",
       "16                                   None                      None   \n",
       "\n",
       "                       10567                       10568           10569  \\\n",
       "0                       None                        None            None   \n",
       "1                       None                        None            None   \n",
       "2                       None                        None            None   \n",
       "3   (gifford-lab/CpGenie, 1)  (braingineer/pyromancy, 1)  (ctb/cvxpy, 1)   \n",
       "4                       None                        None            None   \n",
       "5                       None                        None            None   \n",
       "6                       None                        None            None   \n",
       "7                       None                        None            None   \n",
       "8                       None                        None            None   \n",
       "9                       None                        None            None   \n",
       "10                      None                        None            None   \n",
       "11                      None                        None            None   \n",
       "12                      None                        None            None   \n",
       "13                      None                        None            None   \n",
       "14                      None                        None            None   \n",
       "15                      None                        None            None   \n",
       "16                      None                        None            None   \n",
       "\n",
       "                      10570                       10571  \\\n",
       "0                      None                        None   \n",
       "1                      None                        None   \n",
       "2                      None                        None   \n",
       "3   (pprett/statsmodels, 1)  (ctSkennerton/CompareM, 1)   \n",
       "4                      None                        None   \n",
       "5                      None                        None   \n",
       "6                      None                        None   \n",
       "7                      None                        None   \n",
       "8                      None                        None   \n",
       "9                      None                        None   \n",
       "10                     None                        None   \n",
       "11                     None                        None   \n",
       "12                     None                        None   \n",
       "13                     None                        None   \n",
       "14                     None                        None   \n",
       "15                     None                        None   \n",
       "16                     None                        None   \n",
       "\n",
       "                     10572  \n",
       "0                     None  \n",
       "1                     None  \n",
       "2                     None  \n",
       "3   (shawngraham/SOMPY, 1)  \n",
       "4                     None  \n",
       "5                     None  \n",
       "6                     None  \n",
       "7                     None  \n",
       "8                     None  \n",
       "9                     None  \n",
       "10                    None  \n",
       "11                    None  \n",
       "12                    None  \n",
       "13                    None  \n",
       "14                    None  \n",
       "15                    None  \n",
       "16                    None  \n",
       "\n",
       "[17 rows x 10573 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SklearnMultipleLibraries = pd.DataFrame(SklearnMultipleLibraries)\n",
    "SklearnMultipleLibraries.to_csv(\"sklearn_Multiple_Libaries.csv\")\n",
    "SklearnMultipleLibraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     (KennyCandy/HAR, 74)\n",
       "1                      (mne-tools/mne-tools.github.io, 72)\n",
       "2                             (zooniverse/aggregation, 65)\n",
       "3                                    (bsipocz/astroML, 50)\n",
       "4                                 (kcavagnolo/astroML, 50)\n",
       "5                                (nhuntwalker/astroML, 50)\n",
       "6                                   (eramirem/astroML, 50)\n",
       "7                     (leofdecarvalho/MachineLearning, 44)\n",
       "8                                 (Haunter17/MIR_SU17, 41)\n",
       "9                                      (thast/EOSC513, 36)\n",
       "10                   (parekhmitchell/Machine-Learning, 36)\n",
       "11       (nishantnath/MusicPredictiveAnalysis_EE660_USC...\n",
       "12                              (camallen/aggregation, 34)\n",
       "13                                  (Ernestyj/PyStudy, 33)\n",
       "14                            (mengyun1993/RNN-binary, 33)\n",
       "15                           (rohit21122012/DCASE2013, 32)\n",
       "16                              (TinyOS-Camp/DDEA-DEV, 31)\n",
       "17                      (DistrictDataLabs/yellowbrick, 30)\n",
       "18             (davidvartanian/machine-learning-tests, 27)\n",
       "19                          (cognoma/machine-learning, 27)\n",
       "20                        (amueller/advanced_training, 26)\n",
       "21                                   (probml/pyprobml, 26)\n",
       "22                                  (cjayb/mne-python, 26)\n",
       "23                             (wmvanvliet/mne-python, 26)\n",
       "24                               (adykstra/mne-python, 26)\n",
       "25                        (glemaitre/imbalanced-learn, 26)\n",
       "26                           (chkoar/imbalanced-learn, 26)\n",
       "27                             (pravsripad/mne-python, 26)\n",
       "28                              (annapasca/mne-python, 26)\n",
       "29                              (kambysese/mne-python, 25)\n",
       "                               ...                        \n",
       "10543                                                 None\n",
       "10544                                                 None\n",
       "10545                                                 None\n",
       "10546                                                 None\n",
       "10547                                                 None\n",
       "10548                                                 None\n",
       "10549                                                 None\n",
       "10550                                                 None\n",
       "10551                                                 None\n",
       "10552                                                 None\n",
       "10553                                                 None\n",
       "10554                                                 None\n",
       "10555                                                 None\n",
       "10556                                                 None\n",
       "10557                                                 None\n",
       "10558                                                 None\n",
       "10559                                                 None\n",
       "10560                                                 None\n",
       "10561                                                 None\n",
       "10562                                                 None\n",
       "10563                                                 None\n",
       "10564                                                 None\n",
       "10565                                                 None\n",
       "10566                                                 None\n",
       "10567                                                 None\n",
       "10568                                                 None\n",
       "10569                                                 None\n",
       "10570                                                 None\n",
       "10571                                                 None\n",
       "10572                                                 None\n",
       "Name: 1, Length: 10573, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SklearnMultipleLibraries.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allWithSklearnQuery = \"\"\"\\\n",
    "    SELECT repo_name, line\n",
    "    FROM (\n",
    "          SELECT DISTINCT(line), repo_name, content\n",
    "          FROM(\n",
    "          SELECT (SPLIT(content, '\\\\n')) as lines, repo_name, content\n",
    "          FROM\n",
    "          `Odyssey_github_sklearn.content_py_full`\n",
    "          ), UNNEST(lines) line \n",
    "\n",
    "          WHERE (REGEXP_CONTAINS(line, 'import+ ')) AND %s\n",
    "         )\n",
    "\n",
    "        WHERE (REGEXP_CONTAINS(content, 'from sklearn+  import') OR REGEXP_CONTAINS(content, 'import sklearn+ '))  \n",
    "          \n",
    "         GROUP BY 1,2\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\" %(excludeByRepoFull(excludedRepos))\n",
    "\n",
    "allWithSklearn =gp.run(allWithSklearnQuery)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(dvro/ml, import numpy as np)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(dvro/ml, from sklearn.neighbors.classificatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(dvro/ml, import sklearn as sk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(RDCEP/EDE, from scipy import stats)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(RDCEP/EDE, #import sklearn as sk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(RDCEP/EDE, #from shapely import ops, geometry)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(RDCEP/EDE, import numpy as np)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(obidam/pcm, import sklearn as sk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(obidam/pcm, import pcmpack as PCM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(obidam/pcm, import xarray as xr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(obidam/pcm, import sys)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(obidam/pcm, import unittest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(obidam/pcm, import numpy as np)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(obidam/pcm, from sklearn.utils.estimator_chec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(f00barin/sol, import numpy as np)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(f00barin/sol, import sklearn.datasets as skd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(f00barin/sol, import glob)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(f00barin/sol, import sys)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(f00barin/sol, from __future__ import division)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(f00barin/sol, import sklearn.linear_model as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(f00barin/sol, import sklearn.feature_extracti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(f00barin/sol, import sklearn as sk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(f00barin/sol, import sklearn.svm as sksvm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(rhokgoa/slor, from sklearn.cluster import KMe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(rhokgoa/slor, import numpy as np)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(rhokgoa/slor, import json )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(rhokgoa/slor, import os )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(rhokgoa/slor, import sklearn as sk )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(sidh0/kaggle, import sklearn as sk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(sidh0/kaggle, import pandas as pd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>(satyanugraha/classifying-twitter-user-as-resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>(satyanugraha/classifying-twitter-user-as-resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>(satyanugraha/classifying-twitter-user-as-resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>(satyanugraha/classifying-twitter-user-as-resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>(satyanugraha/classifying-twitter-user-as-resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>(satyanugraha/classifying-twitter-user-as-resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>(satyanugraha/classifying-twitter-user-as-resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>(satyanugraha/classifying-twitter-user-as-resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>(satyanugraha/classifying-twitter-user-as-resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>(DillonNovak/Programming-for-Chemical-Engineer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2180 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0                         (dvro/ml, import numpy as np)\n",
       "1     (dvro/ml, from sklearn.neighbors.classificatio...\n",
       "2                       (dvro/ml, import sklearn as sk)\n",
       "3                  (RDCEP/EDE, from scipy import stats)\n",
       "4                    (RDCEP/EDE, #import sklearn as sk)\n",
       "5       (RDCEP/EDE, #from shapely import ops, geometry)\n",
       "6                       (RDCEP/EDE, import numpy as np)\n",
       "7                    (obidam/pcm, import sklearn as sk)\n",
       "8                   (obidam/pcm, import pcmpack as PCM)\n",
       "9                     (obidam/pcm, import xarray as xr)\n",
       "10                             (obidam/pcm, import sys)\n",
       "11                        (obidam/pcm, import unittest)\n",
       "12                     (obidam/pcm, import numpy as np)\n",
       "13    (obidam/pcm, from sklearn.utils.estimator_chec...\n",
       "14                   (f00barin/sol, import numpy as np)\n",
       "15       (f00barin/sol, import sklearn.datasets as skd)\n",
       "16                          (f00barin/sol, import glob)\n",
       "17                           (f00barin/sol, import sys)\n",
       "18      (f00barin/sol, from __future__ import division)\n",
       "19    (f00barin/sol, import sklearn.linear_model as ...\n",
       "20    (f00barin/sol, import sklearn.feature_extracti...\n",
       "21                 (f00barin/sol, import sklearn as sk)\n",
       "22          (f00barin/sol, import sklearn.svm as sksvm)\n",
       "23    (rhokgoa/slor, from sklearn.cluster import KMe...\n",
       "24                   (rhokgoa/slor, import numpy as np)\n",
       "25                         (rhokgoa/slor, import json )\n",
       "26                           (rhokgoa/slor, import os )\n",
       "27                (rhokgoa/slor, import sklearn as sk )\n",
       "28                 (sidh0/kaggle, import sklearn as sk)\n",
       "29                  (sidh0/kaggle, import pandas as pd)\n",
       "...                                                 ...\n",
       "2150  (satyanugraha/classifying-twitter-user-as-resi...\n",
       "2151  (satyanugraha/classifying-twitter-user-as-resi...\n",
       "2152  (satyanugraha/classifying-twitter-user-as-resi...\n",
       "2153  (satyanugraha/classifying-twitter-user-as-resi...\n",
       "2154  (satyanugraha/classifying-twitter-user-as-resi...\n",
       "2155  (satyanugraha/classifying-twitter-user-as-resi...\n",
       "2156  (satyanugraha/classifying-twitter-user-as-resi...\n",
       "2157  (satyanugraha/classifying-twitter-user-as-resi...\n",
       "2158  (satyanugraha/classifying-twitter-user-as-resi...\n",
       "2159  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2160  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2161  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2162  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2163  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2164  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2165  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2166  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2167  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2168  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2169  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2170  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2171  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2172  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2173  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2174  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2175  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2176  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2177  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2178  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "2179  (DillonNovak/Programming-for-Chemical-Engineer...\n",
       "\n",
       "[2180 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWithSklearn= pd.DataFrame(allWithSklearn)\n",
    "allWithSklearn.to_csv(\"allWithSklearn.csv\") \n",
    "allWithSklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['import numpy as np',\n",
       " 'from sklearn.neighbors.classification import KNeighborsClassifier',\n",
       " 'import sklearn as sk',\n",
       " 'from scipy import stats',\n",
       " '#import sklearn as sk',\n",
       " '#from shapely import ops, geometry',\n",
       " 'import numpy as np',\n",
       " 'import sklearn as sk',\n",
       " 'import pcmpack as PCM',\n",
       " 'import xarray as xr',\n",
       " 'import sys',\n",
       " 'import unittest',\n",
       " 'import numpy as np',\n",
       " 'from sklearn.utils.estimator_checks import check_estimator',\n",
       " 'import numpy as np',\n",
       " 'import sklearn.datasets as skd',\n",
       " 'import glob',\n",
       " 'import sys',\n",
       " 'from __future__ import division',\n",
       " 'import sklearn.linear_model as sklm',\n",
       " 'import sklearn.feature_extraction.text as skfet',\n",
       " 'import sklearn as sk',\n",
       " 'import sklearn.svm as sksvm',\n",
       " 'from sklearn.cluster import KMeans',\n",
       " 'import numpy as np',\n",
       " 'import json ',\n",
       " 'import os ',\n",
       " 'import sklearn as sk ',\n",
       " 'import sklearn as sk',\n",
       " 'import pandas as pd',\n",
       " 'import random',\n",
       " 'import numpy as np',\n",
       " 'import scipy',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'import sklearn.datasets',\n",
       " 'import matplotlib',\n",
       " 'import sklearn.svm',\n",
       " 'import sklearn.cross_validation',\n",
       " 'import sklearn as sl',\n",
       " 'import numpy as np',\n",
       " 'import sklearn.ensemble ',\n",
       " 'import numpy as np ',\n",
       " 'import sklearn.cross_validation ',\n",
       " 'import sklearn.linear_model ',\n",
       " 'import sklearn ',\n",
       " 'import sklearn.metrics',\n",
       " 'import itertools',\n",
       " 'import sklearn as skl',\n",
       " 'import sklearn.metrics  # noqa flake8 importing as a different name',\n",
       " 'import sklearn.feature_extraction  # noqa flake8 importing as a different name',\n",
       " 'import numpy as np',\n",
       " 'from . import matcher',\n",
       " 'import json',\n",
       " 'from sklearn.cluster import MeanShift, estimate_bandwidth',\n",
       " 'import pandas as pd',\n",
       " 'import random',\n",
       " 'import numpy as np',\n",
       " 'import itertools',\n",
       " 'import json',\n",
       " 'import operator',\n",
       " 'import sklearn as sk',\n",
       " 'import pandas',\n",
       " 'from simulation_generator import haplotype_simulator',\n",
       " 'from sklearn import cluster',\n",
       " 'import os',\n",
       " 'import numpy as np',\n",
       " 'import sklearn as learn',\n",
       " 'import scipy',\n",
       " 'import sys',\n",
       " 'import pandas as pd',\n",
       " 'import sklearn as skl',\n",
       " 'from sklearn import metrics',\n",
       " 'import numpy as np',\n",
       " 'import sys # for stderr',\n",
       " 'import xgboost as xgb',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'import sys',\n",
       " 'import datetime',\n",
       " 'import sklearn as sk',\n",
       " 'import numpy as np',\n",
       " 'import pandas as pd',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'from __future__ import division',\n",
       " 'from . import tools',\n",
       " 'from whitening import whiten',\n",
       " 'import sklearn as skl',\n",
       " 'import tensorflow as tf',\n",
       " 'import sklearn as sk',\n",
       " 'import scipy as cp',\n",
       " 'import numpy as np',\n",
       " 'import pandas as pd',\n",
       " 'import csv',\n",
       " 'import sys',\n",
       " 'import sklearn as sk',\n",
       " 'import numpy as np',\n",
       " 'import math',\n",
       " 'from scripts import common',\n",
       " 'from sklearn import ensemble',\n",
       " 'from sklearn.cross_validation import train_test_split',\n",
       " 'import random',\n",
       " 'import sklearn as skl',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'from sklearn.linear_model import LinearRegression',\n",
       " 'import numpy as np',\n",
       " 'import cPickle',\n",
       " 'import pandas as pd',\n",
       " 'import sklearn.linear_model',\n",
       " 'import numpy as np',\n",
       " 'from flask import g',\n",
       " 'import sklearn as skl',\n",
       " 'import sklearn.ensemble',\n",
       " 'import pylab as pl',\n",
       " 'import sklearn.cross_validation',\n",
       " 'import sklearn.svm',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'import sklearn as sl',\n",
       " 'import sklearn.datasets',\n",
       " 'import matplotlib',\n",
       " 'import numpy as np',\n",
       " 'import numpy as np',\n",
       " 'import csv',\n",
       " 'from sklearn.decomposition import PCA',\n",
       " 'from collections import defaultdict',\n",
       " 'from sklearn.cross_validation import train_test_split',\n",
       " 'import sklearn as skl',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'import scipy as sp',\n",
       " 'import prettyplotlib as ppl',\n",
       " 'from sklearn.lda import LDA',\n",
       " 'from datetime import datetime',\n",
       " 'import sklearn as sk',\n",
       " 'from collections import Counter',\n",
       " 'import pandas as pd',\n",
       " 'import numpy as np',\n",
       " 'import sklearn as skl',\n",
       " 'import numpy as np',\n",
       " 'from sklearn.grid_search import GridSearchCV',\n",
       " 'import pylab as pl',\n",
       " 'from sklearn import datasets',\n",
       " 'from sklearn.tree import DecisionTreeRegressor',\n",
       " 'from sklearn.metrics import roc_curve, auc, confusion_matrix',\n",
       " 'import numpy as np',\n",
       " 'import sklearn as sk',\n",
       " 'from math import ceil',\n",
       " 'from keras.models import model_from_json',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'import os',\n",
       " 'import pickle as p',\n",
       " 'import sklearn as skl',\n",
       " 'import sys',\n",
       " 'import shakespeare as shake',\n",
       " 'import numpy as np',\n",
       " 'import numpy as np',\n",
       " 'import sklearn as sk',\n",
       " 'import pandas as pd',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'from Prediction.SplitTrainValid.getCompleteVoteData import getCompleteVoteData',\n",
       " 'from time import time',\n",
       " 'import sklearn as sk',\n",
       " 'from gensim.models.keyedvectors import KeyedVectors',\n",
       " 'import tensorflow as tf',\n",
       " 'import numpy as np',\n",
       " 'import sklearn as sk',\n",
       " 'from qp.utils import infty as default_infty',\n",
       " 'from qp.utils import lims as default_lims',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'from sklearn import mixture',\n",
       " 'import bisect',\n",
       " 'import numpy as np',\n",
       " 'import scipy.interpolate as spi',\n",
       " 'import scipy.optimize as spo',\n",
       " 'import qp',\n",
       " 'import scipy.stats as sps',\n",
       " 'from qp.utils import epsilon as default_eps',\n",
       " 'import sklearn as skl',\n",
       " 'import unittest, random, sys, time',\n",
       " '    import scipy as sp',\n",
       " '    from numpy import loadtxt',\n",
       " 'import h2o, h2o_cmd, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " '    import statsmodels as sm',\n",
       " '    import numpy as np',\n",
       " 'import h2o_print as h2p',\n",
       " '    import statsmodels.api as sm_api',\n",
       " '    import sklearn as sk',\n",
       " '    import statsmodels as sm',\n",
       " '    import statsmodels.api as sm_api',\n",
       " '    import sklearn as sk',\n",
       " 'import unittest, random, sys, time',\n",
       " '    import scipy as sp',\n",
       " 'import h2o, h2o_cmd, h2o_hosts, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " 'import h2o_print as h2p',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " '    import numpy as np',\n",
       " '    from numpy import loadtxt',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " '    import sklearn as sk',\n",
       " 'import h2o, h2o_cmd, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " '    from numpy import loadtxt',\n",
       " '    import numpy as np',\n",
       " '    import statsmodels.api as sm_api',\n",
       " 'import h2o_print as h2p',\n",
       " '    import statsmodels as sm',\n",
       " 'import unittest, random, sys, time',\n",
       " '    import scipy as sp',\n",
       " 'import unittest, random, sys, time',\n",
       " '    import scipy as sp',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " 'import h2o_print as h2p',\n",
       " '    from numpy import loadtxt',\n",
       " '    import statsmodels.api as sm_api',\n",
       " 'import h2o, h2o_cmd, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " '    import statsmodels as sm',\n",
       " '    import numpy as np',\n",
       " '    import sklearn as sk',\n",
       " 'import pandas as pd',\n",
       " '   from sklearn.utils import ConvergenceWarning',\n",
       " 'import isodate',\n",
       " '   import sklearn.exceptions  # >= 0.18',\n",
       " 'import timeseries',\n",
       " 'import testable',\n",
       " 'import numpy as np',\n",
       " 'import warnings',\n",
       " 'import sklearn.linear_model',\n",
       " 'import u',\n",
       " 'import sklearn.linear_model  # not imported by default',\n",
       " 'import sklearn as sk',\n",
       " 'from pprint import pprint',\n",
       " 'from sklearn.feature_selection import RFE',\n",
       " 'from sklearn.model_selection import cross_val_score',\n",
       " 'import random',\n",
       " 'import sklearn as skl',\n",
       " 'import numpy as np',\n",
       " 'from sklearn.feature_selection import SelectKBest',\n",
       " 'import nibabel as nib',\n",
       " 'import pandas as pd',\n",
       " 'from sklearn import svm, linear_model, preprocessing',\n",
       " 'import lib_IO',\n",
       " 'from sklearn.svm import LinearSVC',\n",
       " 'from sklearn.feature_selection import f_classif',\n",
       " 'from sklearn.feature_selection import SelectFromModel',\n",
       " 'from xml.dom import minidom',\n",
       " 'from sklearn.model_selection import GridSearchCV',\n",
       " 'import os',\n",
       " 'from sklearn.feature_selection import VarianceThreshold',\n",
       " 'from sklearn.decomposition import PCA',\n",
       " 'from sklearn import datasets, linear_model',\n",
       " '    import numpy as np',\n",
       " '    import scipy as sp',\n",
       " '    from numpy import loadtxt',\n",
       " '    import statsmodels as sm',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " '    import statsmodels.api as sm_api',\n",
       " '    import sklearn as sk',\n",
       " 'import h2o, h2o_cmd, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " 'import h2o_print as h2p',\n",
       " 'import unittest, random, sys, time',\n",
       " '        from sklearn.externals.six import StringIO',\n",
       " 'import sys',\n",
       " 'import sklearn as sk',\n",
       " 'from sklearn.tree import _tree',\n",
       " 'from xy_proj import *',\n",
       " 'import tshortener',\n",
       " 'from xy_lib import *',\n",
       " 'from sklearn import tree',\n",
       " 'from _xy_dt import *',\n",
       " '    import tshortener',\n",
       " '    import numpy as np',\n",
       " '    import sklearn as sk',\n",
       " '    from numpy import loadtxt',\n",
       " 'import h2o_print as h2p',\n",
       " 'import unittest, random, sys, time',\n",
       " '    import statsmodels.api as sm_api',\n",
       " '    import statsmodels as sm',\n",
       " '    import scipy as sp',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " 'import h2o, h2o_cmd, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " '#from sklearn.manifold import MDS',\n",
       " 'import re',\n",
       " '#from sklearn import cross_validation',\n",
       " '# import cartopy.crs as ccrs',\n",
       " '# from gdata.apps import groups',\n",
       " 'from sklearn.cluster import KMeans',\n",
       " '#    from geopy.point import Point',\n",
       " 'from scipy.interpolate import griddata',\n",
       " '#    import cmath',\n",
       " 'from string import join',\n",
       " '# import pdb',\n",
       " 'from numpy.random.mtrand import seed',\n",
       " '# from sklearn.grid_search import GridSearchCV',\n",
       " '#    from reportlab.platypus import SimpleDocTemplate,Paragraph,Spacer,Table',\n",
       " '#    from scipy import stats',\n",
       " 'from matplotlib import cm',\n",
       " 'import csv',\n",
       " 'import numpy as np',\n",
       " '# from sklearn.cross_validation import train_test_split',\n",
       " 'import shutil',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'from sklearn.svm import SVR',\n",
       " 'import os',\n",
       " 'from matplotlib.pyplot import colors',\n",
       " '    from scipy import interpolate',\n",
       " 'from scipy import signal',\n",
       " '# from procrupy import generalized_procrustes_analysis',\n",
       " '# from sklearn.metrics import confusion_matrix',\n",
       " '        from sklearn.decomposition import PCA',\n",
       " 'from scipy import stats as st',\n",
       " '#    from reportlab.lib.styles import getSampleStyleSheet',\n",
       " '#from sklearn import metrics',\n",
       " 'import pywt',\n",
       " '#from sklearn import svm',\n",
       " '#from sklearn import lda as ld',\n",
       " '#        from shapely.geometry import Polygon',\n",
       " 'import pandas as pd',\n",
       " 'import sklearn as sk',\n",
       " 'import itertools',\n",
       " '#    from geopy.distance import distance',\n",
       " '#import networkx as nx',\n",
       " '#        from scipy import interpolate',\n",
       " '#    from reportlab.lib.units import inch',\n",
       " 'from sklearn.feature_selection import RFE',\n",
       " '        from scipy import interpolate',\n",
       " '# from sklearn.decomposition import RandomizedPCA',\n",
       " '##   import pywt',\n",
       " '# from sklearn.utils.multiclass import unique_labels',\n",
       " '# import cartopy.feature as cfeature ',\n",
       " '# from sklearn.svm import SVC',\n",
       " '# #import csv',\n",
       " '# from osgeo import gdal',\n",
       " 'import random',\n",
       " 'from procrupy import generalized_procrustes_analysis',\n",
       " 'from scipy.spatial.distance import squareform,pdist',\n",
       " '        from shapely.geometry import Polygon',\n",
       " '#from sklearn import preprocessing',\n",
       " '# from sklearn.preprocessing import LabelEncoder',\n",
       " 'import  scipy.cluster.hierarchy as hr',\n",
       " '    import pandas as pd',\n",
       " 'from sklearn.lda import LDA',\n",
       " '# import csv',\n",
       " '# from sklearn.metrics import classification_report',\n",
       " '# import re ',\n",
       " 'from string import atof,split',\n",
       " '#from pyearth import Earth',\n",
       " 'from sklearn.decomposition import PCA',\n",
       " '# import redis, pickle',\n",
       " '    import math',\n",
       " 'import pdb',\n",
       " '    from numpy import loadtxt',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " '    import scipy as sp',\n",
       " '    import sklearn as sk',\n",
       " '    import statsmodels.api as sm_api',\n",
       " '    import numpy as np',\n",
       " 'import h2o, h2o_cmd, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " '    import statsmodels as sm',\n",
       " 'import h2o_print as h2p',\n",
       " 'import unittest, random, sys, time',\n",
       " 'import numpy as np',\n",
       " 'import sys',\n",
       " 'from skimage.io import imread',\n",
       " 'from skimage.transform import resize',\n",
       " 'from sklearn.cross_validation import train_test_split',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'import matplotlib',\n",
       " 'import matplotlib.patches as mpatches',\n",
       " 'from scipy.stats import sem',\n",
       " 'from sklearn import svm',\n",
       " 'from sklearn import metrics',\n",
       " 'from matplotlib import pyplot as plt',\n",
       " 'from scipy.signal import convolve2d',\n",
       " 'from skimage.measure import regionprops',\n",
       " 'from Tkinter import *',\n",
       " 'from skimage.measure import label',\n",
       " 'from skimage.color import label2rgb',\n",
       " 'from skimage.segmentation import clear_border',\n",
       " 'from scipy import ndimage',\n",
       " 'import sklearn as sk',\n",
       " 'from sklearn.svm import SVC',\n",
       " 'from image_extractor import word_segmentation, down_sample',\n",
       " 'from sklearn.cross_validation import cross_val_score, KFold',\n",
       " 'from skimage.filters import threshold_otsu',\n",
       " 'import pickle',\n",
       " 'import unittest',\n",
       " 'from sklearn.linear_model import LinearRegression',\n",
       " 'from lime.lime_text import LimeTextExplainer',\n",
       " 'from sklearn.linear_model import Lasso',\n",
       " '    from sklearn.model_selection import train_test_split',\n",
       " 'import sklearn # noqa',\n",
       " 'from sklearn.datasets import fetch_20newsgroups',\n",
       " 'from sklearn.ensemble import RandomForestClassifier',\n",
       " 'import numpy as np',\n",
       " 'from sklearn.pipeline import make_pipeline',\n",
       " 'import sklearn.linear_model # noqa',\n",
       " 'import sklearn.ensemble',\n",
       " '    from sklearn.cross_validation import train_test_split',\n",
       " 'from lime.discretize import QuartileDiscretizer, DecileDiscretizer, EntropyDiscretizer',\n",
       " 'from sklearn.feature_extraction.text import TfidfVectorizer',\n",
       " 'from sklearn.naive_bayes import MultinomialNB',\n",
       " 'from lime.lime_tabular import LimeTabularExplainer',\n",
       " 'from sklearn.datasets import load_iris, make_classification',\n",
       " 'from sklearn.metrics import f1_score',\n",
       " 'import sklearn.datasets',\n",
       " '    from sklearn.metrics import f1_score as sklearn_f1_score',\n",
       " 'from nilmtk.utils import find_nearest',\n",
       " '    # If we import sklearn at top of file then sphinx breaks.',\n",
       " '    # If we import sklearn at the top of the file then it makes autodoc fail',\n",
       " 'import pandas as pd',\n",
       " 'from nilmtk.datastore import HDFDataStore',\n",
       " '            from sklearn.utils.extmath import cartesian',\n",
       " '    from sklearn.cluster import MeanShift',\n",
       " 'import pandas as pd ',\n",
       " 'import sys',\n",
       " '    import warnings',\n",
       " 'from nilmtk.feature_detectors import cluster',\n",
       " 'from .metergroup import MeterGroup',\n",
       " '    from sklearn import metrics',\n",
       " 'import math',\n",
       " 'import copy',\n",
       " '        import warnings',\n",
       " 'from nilmtk.disaggregate import Disaggregator',\n",
       " 'from warnings import warn',\n",
       " '        # If we import sklearn at the top of the file then auto doc fails.',\n",
       " '    from sklearn.cluster import KMeans',\n",
       " 'import pickle',\n",
       " 'from .metergroup import iterate_through_submeters_of_two_metergroups',\n",
       " 'from __future__ import print_function, division',\n",
       " 'from .electric import align_two_meters',\n",
       " 'import numpy as np',\n",
       " '        from sklearn import tree',\n",
       " 'import time',\n",
       " 'from ut.stats.util import binomial_probs_to_multinomial_probs',\n",
       " 'import scipy.interpolate as interpolate',\n",
       " 'import numpy as np',\n",
       " 'from scipy.optimize import minimize_scalar',\n",
       " 'from ut.stats.classification.bin.base import BinaryClassifierBase2D',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'from numpy import *',\n",
       " 'import sklearn as sk',\n",
       " 'import pandas as pd',\n",
       " '    import statsmodels as sm',\n",
       " '    import scipy as sp',\n",
       " 'import h2o_print as h2p',\n",
       " '    import numpy as np',\n",
       " 'import h2o, h2o_cmd, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " '    from numpy import loadtxt',\n",
       " '    import statsmodels.api as sm_api',\n",
       " '    import sklearn as sk',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " 'import unittest, random, sys, time',\n",
       " '    import scipy as sp',\n",
       " '    import statsmodels as sm',\n",
       " '    import statsmodels.api as sm_api',\n",
       " 'import h2o_print as h2p',\n",
       " 'import unittest, random, sys, time',\n",
       " 'import h2o, h2o_cmd, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " '    from numpy import loadtxt',\n",
       " '    import sklearn as sk',\n",
       " '    import numpy as np',\n",
       " '            from sklearn.utils.extmath import cartesian',\n",
       " 'from warnings import warn',\n",
       " 'from .metergroup import iterate_through_submeters_of_two_metergroups',\n",
       " 'import pickle',\n",
       " 'import pandas as pd ',\n",
       " 'import math',\n",
       " '    import warnings',\n",
       " '    from sklearn.cluster import MeanShift',\n",
       " 'from nilmtk.disaggregate import Disaggregator',\n",
       " 'import copy',\n",
       " '        import warnings',\n",
       " '    from sklearn.cluster import KMeans',\n",
       " 'from .electric import align_two_meters',\n",
       " '    from sklearn import metrics',\n",
       " 'from nilmtk.utils import find_nearest',\n",
       " '    # If we import sklearn at top of file then sphinx breaks.',\n",
       " 'import pandas as pd',\n",
       " '    from sklearn.metrics import f1_score as sklearn_f1_score',\n",
       " 'from nilmtk.electric import get_vampire_power',\n",
       " 'from nilmtk.feature_detectors import cluster',\n",
       " 'import sys',\n",
       " 'from __future__ import print_function, division',\n",
       " 'from nilmtk.datastore import HDFDataStore',\n",
       " 'import numpy as np',\n",
       " '        # If we import sklearn at the top of the file then auto doc fails.',\n",
       " '    # If we import sklearn at the top of the file then it makes autodoc fail',\n",
       " 'from .metergroup import MeterGroup',\n",
       " 'import pandas as pd',\n",
       " 'import subprocess',\n",
       " 'from collections import defaultdict',\n",
       " 'import numpy as np',\n",
       " 'import os',\n",
       " 'import logging',\n",
       " 'from pprint import pprint',\n",
       " 'import json',\n",
       " 'import simindex.helper as hp',\n",
       " 'from .similarity import SimLearner',\n",
       " 'from .dysim import MDySimIII',\n",
       " 'import pickle',\n",
       " 'import sklearn as skm',\n",
       " 'from .weak_labels import WeakLabels, \\\\',\n",
       " 'from .fusionlearner import FusionLearner',\n",
       " 'import numpy as np',\n",
       " '    >>> from sklearn import datasets',\n",
       " '    >>> from pyspark.ml.feature import HashingTF, Tokenizer',\n",
       " '    >>> from systemml.mllearn import LogisticRegression',\n",
       " '    >>> from pyspark.sql import SparkSession',\n",
       " 'from pyspark.sql import DataFrame',\n",
       " '    >>> import numpy as np',\n",
       " 'import traceback',\n",
       " 'from pyspark.ml import Estimator',\n",
       " 'from sklearn.metrics import accuracy_score, r2_score',\n",
       " '    >>> from systemml.mllearn import Caffe2DML',\n",
       " 'from py4j.protocol import Py4JError',\n",
       " 'from ..converters import *',\n",
       " '    >>> from sklearn.datasets import fetch_20newsgroups',\n",
       " 'from sklearn.preprocessing import LabelEncoder',\n",
       " '    >>> from sklearn.feature_extraction.text import TfidfVectorizer',\n",
       " 'import time',\n",
       " '    >>> from systemml.mllearn import NaiveBayes',\n",
       " 'import threading',\n",
       " 'import sklearn as sk',\n",
       " '        import pyspark',\n",
       " '    >>> from sklearn import metrics',\n",
       " '    >>> from sklearn import datasets, neighbors',\n",
       " 'from ..classloader import *',\n",
       " 'import math',\n",
       " '    >>> from systemml.mllearn import SVM',\n",
       " '    >>> import urllib',\n",
       " '        from pyspark.sql.dataframe import DataFrame as df',\n",
       " '    >>> from sklearn.utils import shuffle',\n",
       " '    >>> from systemml.mllearn import LinearRegression',\n",
       " '    >>> from mlxtend.data import mnist_data',\n",
       " 'from pyspark.ml.feature import VectorAssembler',\n",
       " '    >>> from pyspark.ml import Pipeline',\n",
       " 'from ..timeframe import merge_timeframes, TimeFrame',\n",
       " 'from datetime import datetime',\n",
       " 'import pandas as pd ',\n",
       " 'from __future__ import print_function, division',\n",
       " '    import warnings',\n",
       " '        from sklearn.utils.extmath import cartesian',\n",
       " 'from ..feature_detectors import cluster',\n",
       " '        # If we import sklearn at the top of the file then auto doc fails.',\n",
       " 'from ..utils import find_nearest',\n",
       " 'import sys',\n",
       " 'from nilmtk.exceptions import VampirePowerAlreadyInModelError',\n",
       " 'import math',\n",
       " '    from sklearn.cluster import KMeans',\n",
       " '    from sklearn.metrics import f1_score as sklearn_f1_score',\n",
       " '    # If we import sklearn at top of file then sphinx breaks.',\n",
       " '    # If we import sklearn at the top of the file then it makes autodoc fail',\n",
       " '    from sklearn import metrics',\n",
       " 'import pandas as pd',\n",
       " 'from .metergroup import MeterGroup, iterate_through_submeters_of_two_metergroups',\n",
       " '    from sklearn.cluster import MeanShift',\n",
       " 'from .electric import align_two_meters',\n",
       " 'import numpy as np',\n",
       " '        import warnings',\n",
       " 'import sklearn.svm',\n",
       " 'import numpy as np',\n",
       " 'import random',\n",
       " 'import time',\n",
       " 'import datetime',\n",
       " 'import notifier',\n",
       " 'import matplotlib',\n",
       " 'import sklearn.feature_extraction.text ',\n",
       " 'from nltk.corpus import reuters',\n",
       " 'import sklearn.model_selection',\n",
       " 'import sklearn as sl',\n",
       " 'import nltk',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " '# This code could be in a separate file and import the dictionary   #',\n",
       " '        import StringIO',\n",
       " 'from dbapi import ActivityRegister, getUserRegister, humanActivityCreditsExpire',\n",
       " 'from dbapi import formatDate, createUserRegisterDB, dateTime2EpochString, createAppointmentDB, getActivitiesNames',\n",
       " 'import json',\n",
       " '        from sklearn import tree',\n",
       " '        from sklearn.preprocessing import LabelEncoder',\n",
       " 'import locale',\n",
       " '        from sklearn.cross_validation import train_test_split',\n",
       " '          import vobject',\n",
       " '        from IPython.core.display import Image',\n",
       " '      from datetime import datetime',\n",
       " '#    import sklearn as sk',\n",
       " '        from forecastiopy import ForecastIO',\n",
       " 'import time',\n",
       " '#    import numpy as np',\n",
       " 'import commands',\n",
       " 'import numpy as np',\n",
       " 'import os',\n",
       " 'import sys',\n",
       " 'import common',\n",
       " 'import logging',\n",
       " 'from draw import drawLines',\n",
       " 'import sklearn as sk',\n",
       " 'import numpy as nu',\n",
       " 'import pickle',\n",
       " 'import gc',\n",
       " 'from sklearn.cluster import KMeans',\n",
       " 'import skimage.restoration',\n",
       " 'from IPython.core.debugger import Tracer',\n",
       " 'from echonet.utils.generics import generate_delta, load_audio, to_one_hot',\n",
       " 'import subprocess',\n",
       " 'import skimage as skim',\n",
       " 'import numpy as np',\n",
       " 'from tqdm import tqdm',\n",
       " 'import xml.etree.ElementTree',\n",
       " 'from collections import OrderedDict',\n",
       " 'import skimage.measure',\n",
       " 'import sklearn.model_selection',\n",
       " 'import pandas as pd',\n",
       " 'import librosa',\n",
       " 'import sklearn as sk',\n",
       " 'from echonet.datasets.dataset import Dataset',\n",
       " 'import skimage.morphology',\n",
       " 'import os',\n",
       " '        import sparkonda',\n",
       " 'import ConfigParser',\n",
       " 'import os.path',\n",
       " 'from pyspark import SparkConf',\n",
       " 'from nose.plugins.attrib import attr',\n",
       " 'import sparkonda as skon',\n",
       " 'import logging',\n",
       " 'from pyspark import SparkContext',\n",
       " '            import sparkonda_utils as skon',\n",
       " '        # Helper to import the sparkonda_utils module',\n",
       " 'from nose.tools import assert_true, assert_equal',\n",
       " 'import sys',\n",
       " '            import pandas as pd',\n",
       " '        from os.path import expanduser',\n",
       " 'def d(x): import pandas as pd; return pd.__version__',\n",
       " '            import sparkonda.sparkonda_utils as skon',\n",
       " 'from __future__ import print_function',\n",
       " 'from os.path import expanduser',\n",
       " '            import sklearn as sk',\n",
       " 'try: import sparkonda.sparkonda as skon',\n",
       " 'import unittest',\n",
       " 'def d(x): import sklearn as sk; return sk.__version__',\n",
       " '    >>> from systemml.mllearn import NaiveBayes',\n",
       " '        from . import keras2caffe',\n",
       " 'from sklearn.preprocessing import LabelEncoder',\n",
       " '    >>> from systemml.mllearn import LinearRegression',\n",
       " '    >>> from systemml.mllearn import SVM',\n",
       " 'import threading',\n",
       " 'from sklearn.metrics import accuracy_score, r2_score',\n",
       " 'import numpy as np',\n",
       " 'from pyspark.sql import DataFrame',\n",
       " '    >>> from pyspark.sql import SparkSession',\n",
       " '        import pyspark',\n",
       " '    >>> from systemml.mllearn import LogisticRegression',\n",
       " '    >>> from sklearn.datasets import fetch_20newsgroups',\n",
       " '    >>> from sklearn.utils import shuffle',\n",
       " '    >>> from sklearn import datasets, neighbors',\n",
       " 'import traceback',\n",
       " '    >>> from sklearn import metrics',\n",
       " '    >>> from sklearn import datasets',\n",
       " 'from ..classloader import *',\n",
       " '    >>> from sklearn.feature_extraction.text import TfidfVectorizer',\n",
       " '    >>> from mlxtend.data import mnist_data',\n",
       " 'import sklearn as sk',\n",
       " '        from pyspark.sql.dataframe import DataFrame as df',\n",
       " '    >>> import urllib',\n",
       " 'from pyspark.ml.feature import VectorAssembler',\n",
       " 'from ..converters import *',\n",
       " 'import math',\n",
       " 'from pyspark.ml import Estimator',\n",
       " '    >>> from pyspark.ml.feature import HashingTF, Tokenizer',\n",
       " 'import time',\n",
       " '    >>> from systemml.mllearn import Caffe2DML',\n",
       " '    >>> from pyspark.ml import Pipeline',\n",
       " '    >>> import numpy as np',\n",
       " 'from py4j.protocol import Py4JError',\n",
       " '    # If we import sklearn at the top of the file then it makes autodoc fail',\n",
       " 'from ..feature_detectors import cluster',\n",
       " '    from sklearn import metrics',\n",
       " '    from sklearn.metrics import f1_score as sklearn_f1_score',\n",
       " '    import warnings',\n",
       " '        from sklearn.utils.extmath import cartesian',\n",
       " 'from ..timeframe import merge_timeframes, TimeFrame',\n",
       " 'from .metergroup import MeterGroup, iterate_through_submeters_of_two_metergroups',\n",
       " 'import numpy as np',\n",
       " '    # If we import sklearn at top of file then sphinx breaks.',\n",
       " '        import warnings',\n",
       " '        # If we import sklearn at the top of the file then auto doc fails.',\n",
       " '    from sklearn.cluster import KMeans',\n",
       " 'import pandas as pd ',\n",
       " '    from sklearn.cluster import MeanShift',\n",
       " 'import math',\n",
       " 'import pandas as pd',\n",
       " 'import sys',\n",
       " 'from datetime import datetime',\n",
       " 'from nilmtk.exceptions import VampirePowerAlreadyInModelError',\n",
       " 'from .electric import align_two_meters',\n",
       " 'from __future__ import print_function, division',\n",
       " 'from ..utils import find_nearest',\n",
       " 'from sklearn.linear_model import LinearRegression',\n",
       " 'from . import Utils as tsutil',\n",
       " 'import pandas as pd',\n",
       " 'from . import Time as tsti',\n",
       " 'import datetime',\n",
       " 'import sklearn.linear_model as linear_model',\n",
       " 'from . import Perf as tsperf',\n",
       " 'import sklearn as skl',\n",
       " 'from . import Plots as tsplot',\n",
       " 'import sklearn.preprocessing as preprocessing',\n",
       " 'from sklearn.feature_selection import RFE',\n",
       " 'import numpy as np',\n",
       " '    import sklearn as sk',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " 'import h2o, h2o_cmd, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " '    import scipy as sp',\n",
       " '    import statsmodels as sm',\n",
       " 'import h2o_print as h2p',\n",
       " '    import numpy as np',\n",
       " '    import statsmodels.api as sm_api',\n",
       " '    from numpy import loadtxt',\n",
       " 'import unittest, random, sys, time',\n",
       " '    >>> from sklearn import metrics',\n",
       " 'from ..classloader import *',\n",
       " '        import pyspark',\n",
       " '    >>> from sklearn.feature_extraction.text import TfidfVectorizer',\n",
       " '    >>> from mlxtend.data import mnist_data',\n",
       " '        from pyspark.sql.dataframe import DataFrame as df',\n",
       " '    >>> import numpy as np',\n",
       " '    >>> from pyspark.ml.feature import HashingTF, Tokenizer',\n",
       " 'from pyspark.sql import DataFrame',\n",
       " '    >>> from systemml.mllearn import Caffe2DML',\n",
       " '    >>> from sklearn.datasets import fetch_20newsgroups',\n",
       " '    >>> from sklearn import datasets, neighbors',\n",
       " '    >>> from sklearn.utils import shuffle',\n",
       " '    >>> from sklearn import datasets',\n",
       " 'from sklearn.metrics import accuracy_score, r2_score',\n",
       " '    >>> from pyspark.sql import SparkSession',\n",
       " '    >>> import urllib',\n",
       " '    >>> from systemml.mllearn import LogisticRegression',\n",
       " 'import numpy as np',\n",
       " 'import time',\n",
       " 'from pyspark.ml import Estimator',\n",
       " 'from py4j.protocol import Py4JError',\n",
       " 'import sklearn as sk',\n",
       " 'import math',\n",
       " '    >>> from systemml.mllearn import SVM',\n",
       " '    >>> from systemml.mllearn import LinearRegression',\n",
       " '        from . import keras2caffe',\n",
       " '    >>> from systemml.mllearn import NaiveBayes',\n",
       " 'import traceback',\n",
       " '    >>> from pyspark.ml import Pipeline',\n",
       " 'import threading',\n",
       " 'from sklearn.preprocessing import LabelEncoder',\n",
       " 'from ..converters import *',\n",
       " 'from pyspark.ml.feature import VectorAssembler',\n",
       " 'from nilmtk.exceptions import VampirePowerAlreadyInModelError',\n",
       " 'import pandas as pd ',\n",
       " '    import warnings',\n",
       " '    from sklearn.cluster import KMeans',\n",
       " 'from ..feature_detectors import cluster',\n",
       " 'from ..timeframe import merge_timeframes, TimeFrame',\n",
       " 'from .electric import align_two_meters',\n",
       " '        import warnings',\n",
       " '    # If we import sklearn at the top of the file then it makes autodoc fail',\n",
       " 'from ..utils import find_nearest',\n",
       " 'import pandas as pd',\n",
       " '    # If we import sklearn at top of file then sphinx breaks.',\n",
       " '    from sklearn import metrics',\n",
       " '    from sklearn.metrics import f1_score as sklearn_f1_score',\n",
       " '    from sklearn.cluster import MeanShift',\n",
       " 'from datetime import datetime',\n",
       " 'from .metergroup import MeterGroup, iterate_through_submeters_of_two_metergroups',\n",
       " 'import sys',\n",
       " 'import numpy as np',\n",
       " '        from sklearn.utils.extmath import cartesian',\n",
       " '        # If we import sklearn at the top of the file then auto doc fails.',\n",
       " 'from __future__ import print_function, division',\n",
       " 'import math',\n",
       " '    from sklearn.cluster import KMeans',\n",
       " '    from sklearn.metrics import f1_score as sklearn_f1_score',\n",
       " 'from nilmtk.exceptions import VampirePowerAlreadyInModelError',\n",
       " 'from ..feature_detectors import cluster',\n",
       " 'from ..timeframe import merge_timeframes, TimeFrame',\n",
       " 'import pandas as pd ',\n",
       " '    import warnings',\n",
       " 'import sys',\n",
       " 'import pandas as pd',\n",
       " '    from sklearn.cluster import MeanShift',\n",
       " 'from .electric import align_two_meters',\n",
       " 'from .metergroup import MeterGroup, iterate_through_submeters_of_two_metergroups',\n",
       " '        from sklearn.utils.extmath import cartesian',\n",
       " 'import math',\n",
       " '    from sklearn import metrics',\n",
       " '        import warnings',\n",
       " 'from ..utils import find_nearest',\n",
       " '    # If we import sklearn at the top of the file then it makes autodoc fail',\n",
       " 'from __future__ import print_function, division',\n",
       " '    # If we import sklearn at top of file then sphinx breaks.',\n",
       " '        # If we import sklearn at the top of the file then auto doc fails.',\n",
       " 'from datetime import datetime',\n",
       " 'import numpy as np',\n",
       " 'import numpy as np',\n",
       " 'from pprint import pprint',\n",
       " 'import os',\n",
       " 'import sklearn.preprocessing as prep',\n",
       " 'import sklearn.metrics as met',\n",
       " 'import pandas as pd',\n",
       " 'import base_wrapper',\n",
       " '    import hybridforest',\n",
       " 'import sklearn.pipeline as pip',\n",
       " 'import sklearn.cross_validation as xv',\n",
       " 'import sklearn as sk',\n",
       " 'import sklearn.ensemble as ensemble',\n",
       " 'from ..converters import *',\n",
       " '    >>> from sklearn.datasets import fetch_20newsgroups',\n",
       " '    >>> from sklearn.utils import shuffle',\n",
       " 'from pyspark.sql import DataFrame',\n",
       " '    >>> from sklearn.feature_extraction.text import TfidfVectorizer',\n",
       " 'import numpy as np',\n",
       " '    >>> from systemml.mllearn import LogisticRegression',\n",
       " 'import threading',\n",
       " 'from ..classloader import *',\n",
       " '    >>> import numpy as np',\n",
       " '    >>> from systemml.mllearn import NaiveBayes',\n",
       " 'import time',\n",
       " '    >>> from sklearn import metrics',\n",
       " 'import sklearn as sk',\n",
       " '    >>> from sklearn import datasets',\n",
       " '    >>> from pyspark.sql import SparkSession',\n",
       " '    >>> from systemml.mllearn import Caffe2DML',\n",
       " '    >>> from sklearn import datasets, neighbors',\n",
       " 'import traceback',\n",
       " 'from py4j.protocol import Py4JError',\n",
       " '    >>> from mlxtend.data import mnist_data',\n",
       " '    >>> from systemml.mllearn import SVM',\n",
       " '        from pyspark.sql.dataframe import DataFrame as df',\n",
       " '    >>> from systemml.mllearn import LinearRegression',\n",
       " 'import math',\n",
       " '    >>> from pyspark.ml import Pipeline',\n",
       " '    >>> from pyspark.ml.feature import HashingTF, Tokenizer',\n",
       " 'from sklearn.metrics import accuracy_score, r2_score',\n",
       " 'from pyspark.ml import Estimator',\n",
       " 'from sklearn.preprocessing import LabelEncoder',\n",
       " '    >>> import urllib',\n",
       " 'from pyspark.ml.feature import VectorAssembler',\n",
       " '            from sklearn.svm import SVC, SVR, LinearSVC',\n",
       " 'from sandbox.util.Evaluator import Evaluator',\n",
       " '            from sklearn.svm import SVC, SVR',\n",
       " 'import numpy',\n",
       " 'import scipy',\n",
       " 'import scipy.sparse',\n",
       " 'from sandbox.util.Parameter import Parameter',\n",
       " '            from sklearn.svm import SVC ',\n",
       " '            from sklearn.svm import SVC',\n",
       " 'from sandbox.predictors.AbstractPredictor import AbstractPredictor',\n",
       " 'import sklearn ',\n",
       " '    import statsmodels as sm',\n",
       " 'import unittest, random, sys, time',\n",
       " '    from sklearn.linear_model import LogisticRegression',\n",
       " '    from numpy import loadtxt',\n",
       " '    import numpy as np',\n",
       " '    import sklearn as sk',\n",
       " '    import scipy as sp',\n",
       " 'import h2o, h2o_cmd, h2o_import as h2i, h2o_exec, h2o_glm, h2o_jobs',\n",
       " '    import statsmodels.api as sm_api',\n",
       " 'import h2o_print as h2p',\n",
       " 'import copy',\n",
       " 'import re',\n",
       " 'from sklearn.tree import DecisionTreeClassifier',\n",
       " 'import numpy as np',\n",
       " 'from sklearn.neighbors import KNeighborsClassifier',\n",
       " 'from sklearn.gaussian_process import GaussianProcessClassifier',\n",
       " 'from sklearn.base import clone',\n",
       " 'from xgboost.sklearn import XGBClassifier',\n",
       " 'from sklearn.preprocessing import LabelEncoder',\n",
       " 'from sklearn.model_selection import KFold, cross_val_score, GridSearchCV',\n",
       " 'import sklearn as skl',\n",
       " 'from sklearn.neural_network import MLPClassifier',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'from sklearn.ensemble import RandomForestClassifier, VotingClassifier, ExtraTreesClassifier, AdaBoostClassifier',\n",
       " 'from sklearn.gaussian_process.kernels import RBF',\n",
       " 'from sklearn.svm import SVC',\n",
       " 'import pandas as pd',\n",
       " 'from numpy.random import multivariate_normal, uniform, random_integers',\n",
       " 'import csv',\n",
       " 'from numpy import zeros, array, eye',\n",
       " 'import sklearn.linear_model as lm',\n",
       " 'from sklearn.covariance import GraphLasso',\n",
       " '    from pysnptools.pysnptools.snpreader.bed import Bed',\n",
       " '    import fastlmm.util.standardizer as stdizer',\n",
       " '    import fastlmm.pyplink.plink as plink',\n",
       " 'from screening_elastic_net_path import ScreeningElasticNetPath',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'from solver import SklearnCDSolver, ActiveSetCDSolver, ProximalGradientSolver, AccelProximalGradientSolver',\n",
       " 'import scipy.sparse as sparse',\n",
       " 'import numpy as np',\n",
       " 'import sklearn as sk',\n",
       " 'from screening_rules import *',\n",
       " '    import pysnptools.pysnptools.util.util',\n",
       " 'from neighbor_select import NeighborSelect ',\n",
       " 'import scipy.optimize as opt',\n",
       " 'import sklearn as skl',\n",
       " 'import time',\n",
       " '    >>> from sklearn.datasets import fetch_20newsgroups',\n",
       " 'from sklearn.metrics import accuracy_score, r2_score',\n",
       " 'import traceback',\n",
       " '    >>> from sklearn.feature_extraction.text import TfidfVectorizer',\n",
       " 'import threading',\n",
       " 'import math',\n",
       " 'from pyspark.ml import Estimator',\n",
       " 'from sklearn.preprocessing import LabelEncoder',\n",
       " 'from pyspark.sql import DataFrame',\n",
       " '    >>> from systemml.mllearn import SVM',\n",
       " '    >>> from pyspark.ml import Pipeline',\n",
       " '    >>> from systemml.mllearn import NaiveBayes',\n",
       " '    >>> from pyspark.sql import SQLContext',\n",
       " '    >>> from systemml.mllearn import LinearRegression',\n",
       " '    >>> from pyspark.ml.feature import HashingTF, Tokenizer',\n",
       " '    >>> import numpy as np',\n",
       " 'from py4j.protocol import Py4JError',\n",
       " 'import time',\n",
       " '    >>> from sklearn import datasets',\n",
       " 'from ..classloader import *',\n",
       " 'import numpy as np',\n",
       " 'from ..converters import *',\n",
       " '    >>> from sklearn import metrics',\n",
       " '    >>> from systemml.mllearn import LogisticRegression',\n",
       " '    >>> from sklearn import datasets, neighbors',\n",
       " 'from pyspark.ml.feature import VectorAssembler',\n",
       " 'import sklearn as sk',\n",
       " '    from sklearn.semi_supervised import (LabelPropagation, LabelSpreading)',\n",
       " '    from sklearn.datasets import (',\n",
       " '    from itertools import combinations_with_replacement',\n",
       " 'import time',\n",
       " '    from scipy import signal',\n",
       " '    from sklearn.linear_model import (',\n",
       " '    from scipy import stats',\n",
       " 'from fnmatch import fnmatch, fnmatchcase',\n",
       " '    from sklearn.gaussian_process import GaussianProcessClassifier',\n",
       " '        from sklearn.model_selection import train_test_split',\n",
       " '    import sympy',\n",
       " '    from pylab import (arcsin, arcsinh, arctanh, arctan, arctan2, arccosh,',\n",
       " '    import scipy',\n",
       " '    from sklearn.feature_extraction.text import (',\n",
       " '    import autosklearn',\n",
       " 'from zipfile import ZipFile',\n",
       " 'import zlib',\n",
       " '    from sklearn.cluster import KMeans, MiniBatchKMeans',\n",
       " '# >>> import pylab, math',\n",
       " '    import statsmodels',\n",
       " '    import tensorflow as tf',\n",
       " 'import re',\n",
       " '    from networkx import (',\n",
       " '    from autosklearn.classification import AutoSklearnClassifier',\n",
       " '>>> from everything import *',\n",
       " '    import numpy as np',\n",
       " '    from itertools import ifilter, ifilterfalse, imap, izip, izip_longest',\n",
       " 'from os.path import (abspath, basename, dirname, exists, expanduser, isdir,',\n",
       " '    import pandas as pd',\n",
       " '        from sklearn.cross_validation import train_test_split',\n",
       " '    from sklearn.dummy import DummyClassifier, DummyRegressor',\n",
       " '    import scipy.io.wavfile',\n",
       " 'from re import (DOTALL, IGNORECASE, MULTILINE, UNICODE, VERBOSE,',\n",
       " 'from glob import glob',\n",
       " '    from db import DB',\n",
       " 'from os import chdir, chmod, getcwd, listdir, walk',\n",
       " 'from decimal import Decimal',\n",
       " '    import sklearn     # scikit-learn',\n",
       " 'import collections',\n",
       " '    import math',\n",
       " '    from sklearn.preprocessing import (',\n",
       " '    from pylab import *',\n",
       " '        from io import StringIO',\n",
       " '    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier',\n",
       " '    import networkx as nx',\n",
       " '    from sklearn.naive_bayes import (BernoulliNB, GaussianNB, MultinomialNB)',\n",
       " 'from base64 import b16decode, b16encode, b32decode, b32encode, \\\\',\n",
       " \"- pylab (everything by 'from pylab import *')\",\n",
       " 'from copy import deepcopy',\n",
       " '    import statsmodels.api as sm',\n",
       " 'from sys import stderr, stdin, stdout',\n",
       " '    from sklearn.manifold import TSNE',\n",
       " '    from ConfigParser import ConfigParser',\n",
       " '    import statsmodels.formula.api as smf',\n",
       " 'from collections import (Container, Iterable, Mapping, Sequence,',\n",
       " '    # Should we import urllib?',\n",
       " '    import scipy.spatial',\n",
       " '    from sklearn.tree import DecisionTreeClassifier',\n",
       " 'import json',\n",
       " '    from sklearn.svm import (LinearSVC, OneClassSVM, SVC)',\n",
       " 'import inspect',\n",
       " 'from struct import pack, unpack',\n",
       " '    from configparser import ConfigParser',\n",
       " 'import heapq',\n",
       " 'import sys',\n",
       " 'from datetime import date, datetime, timedelta',\n",
       " '    import sparql',\n",
       " 'import struct',\n",
       " 'from pprint import pprint',\n",
       " '        from StringIO import StringIO',\n",
       " '    from scipy import sqrt',\n",
       " '    from collections import Counter, OrderedDict',\n",
       " 'from itertools import (chain, combinations, count, cycle, dropwhile,',\n",
       " 'import base64',\n",
       " '    from math import *',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfLibraries=[]\n",
    "for i in range(len(allWithSklearn[0])):\n",
    "    listOfLibraries.append(allWithSklearn[0][i][1])\n",
    "\n",
    "listOfLibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
